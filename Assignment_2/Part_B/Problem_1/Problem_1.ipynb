{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_B.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU_wmnaNVFhO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import pathlib\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet152 import ResNet152\n",
        "from keras.applications.resnet152v2 import ResNet152V2\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Dense, GlobalMaxPooling2D\n",
        "from tensorflow.keras.optimizers import Optimizer"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUFbS5KRYipF",
        "outputId": "6a7d7403-cc7c-4693-9e29-ccde228217db"
      },
      "source": [
        "############################### caution : terminal commands ###########################################\n",
        "\n",
        "#-----------------------------empty the datasets forlder before downloading the dataset ------------------------\n",
        "\n",
        "%cd\n",
        "%cd .keras/datasets/\n",
        "!rm -r *"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/root/.keras/datasets\n",
            "rm: cannot remove '*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWz2g5jsFWMQ",
        "outputId": "85a83840-978b-4246-8e34-99d131f1f936"
      },
      "source": [
        "############################### download data from given url ###################################3\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "data_dir = tf.keras.utils.get_file('nature_12K', origin=dataset_url, extract=True)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "3816693760/3816687935 [==============================] - 44s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGGDdWOvFYWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e3a63c-5894-4e60-8655-dd427e8a1bd7"
      },
      "source": [
        "#------------------------------caution : terminal commands --------------------------------------\n",
        "\n",
        "%cd\n",
        "%cd .keras/datasets/inaturalist_12K\n",
        "%mv val test\n",
        "!mkdir valid"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/root/.keras/datasets/inaturalist_12K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQJIOff7RWOf"
      },
      "source": [
        "###################### split train data into validation set and training set ##########################\n",
        "\n",
        "data_folder = '/root/.keras/datasets/inaturalist_12K'\n",
        "os.chdir(data_folder)\n",
        "\n",
        "folder_names = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia' ]\n",
        "for i in range(0,10):\n",
        "  source = data_folder + \"/train/\" +folder_names[i]  \n",
        "  orig_files = os.listdir(source)\n",
        "  chosen_indexes = random.sample(range(0, len(orig_files)-1), 100)\n",
        "\n",
        "  destination = data_folder + \"/valid/\"\n",
        "  os.chdir(destination)\n",
        "  os.system('mkdir'+' '+str(folder_names[i]))\n",
        "  destination = destination + folder_names[i]\n",
        "  for j in range(0,100):\n",
        "    shutil.move(   source +\"/\" + str(   orig_files[   chosen_indexes[j]  ]   )  , destination)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9fn2_KiRWKZ"
      },
      "source": [
        "######################## Correcting the directory location #################################\n",
        "\n",
        "#data_dir = '/root/.keras/datasets/nature_12K'\n",
        "\n",
        "data_dir = data_dir.split('/')\n",
        "data_dir.remove('nature_12K')\n",
        "data_dir.append('inaturalist_12K')\n",
        "data_dir = '/'.join(data_dir)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTM_1UNdRWHn"
      },
      "source": [
        "#----------------------------Taking the train data---------------------------------------------\n",
        "train_data_dir_path = data_dir + '/train'\n",
        "train_data_dir = pathlib.Path(train_data_dir_path)\n",
        "\n",
        "#----------------------------Taking the validation data---------------------------------------\n",
        "valid_data_dir_path = data_dir + '/valid'\n",
        "valid_data_dir = pathlib.Path(valid_data_dir_path)\n",
        "\n",
        "#-----------------------------Taking the test data----------------------------------------\n",
        "test_data_dir_path = data_dir + '/test'\n",
        "test_data_dir = pathlib.Path(test_data_dir_path)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9lMEAEfRbjO"
      },
      "source": [
        "#----------------------------Parameters for the images----------------------------------------\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDPv0DjeRbf_",
        "outputId": "451185a9-fd40-408f-d7e9-848f577b4c86"
      },
      "source": [
        "########################### converting the image data into dataset ##############################\n",
        "\n",
        "#--------------------------training dataset ---------------------------------------\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  label_mode=\"categorical\"\n",
        "  )\n",
        "\n",
        "#-------------------------validation dataset ----------------------------------\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  valid_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  label_mode=\"categorical\"\n",
        "  )"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 files belonging to 10 classes.\n",
            "Found 999 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpage8SfRbdu"
      },
      "source": [
        "######################################## function for using trained model ###############################\n",
        "\n",
        "\n",
        "def get_desired_model(base_model, input_shape=(180,180,3), num_dense_neurons=1014,activation=\"relu\",activation2=\"softmax\",dropout=None, pooling=\"max\",l_rate=0.0001): \n",
        "    \n",
        "    base = base_model(input_shape=input_shape,include_top=False,weights='imagenet') \n",
        "  \n",
        "  #------------------------------ perform pooling --------------------------------------\n",
        "    if pooling == \"avg\": \n",
        "        x = GlobalAveragePooling2D()(base.output) \n",
        "    elif pooling == \"max\": \n",
        "        x = GlobalMaxPooling2D()(base.output) \n",
        "\n",
        "  #---------------------------- Flatten the output  --------------------------------------\n",
        "\n",
        "    x = layers.Flatten()(base.output)\n",
        "\n",
        "\n",
        "  #------------------------------- dropout ---------------------------------------------\n",
        "    if dropout is not None: \n",
        "        x = Dropout(dropout)(x) \n",
        "\n",
        "  #----------------------------- add fully connected layer ---------------------------------\n",
        "    x = Dense(num_dense_neurons, activation=activation)(x) \n",
        "\n",
        "  #------------------------------- and a logistic layer -------------------------------------\n",
        "    x = Dense(10, activation=activation2)(x) \n",
        "\n",
        "  #----------------------------------- get model ----------------------------------------------\n",
        "    model = Model(inputs=base.input, outputs=x) \n",
        "\n",
        "  #--------------------------------- setting the trainable layers -------------------------------\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        " #------------------------------------compiling the model -----------------------------------------\n",
        "    model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"], optimizer=Adam(l_rate)) \n",
        "    \n",
        "  #-------------------------------------return model -------------------------------------------------\n",
        "    return model\n",
        "\n",
        "#============================== end of get_desired_model function ========================================"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDkA7mu6RxFk",
        "outputId": "6066b0d9-67ec-4208-94ca-a4fe0a01ddc6"
      },
      "source": [
        "#---------------------- using MobileNet model as base model ----------------------------------\n",
        "base_model=ResNet50\n",
        "\n",
        "\n",
        "\n",
        "#----------------------- calling function get desired model ----------------------------------\n",
        "model=get_desired_model(base_model, input_shape=(180,180,3), num_dense_neurons=1014 ,activation=\"relu\", activation2=\"softmax\",dropout=None, pooling=\"max\",l_rate=0.0001)\n",
        "\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrniEm-WUUG3",
        "outputId": "8bbe5373-c250-4332-cd65-a37e159cdfef"
      },
      "source": [
        "#--------------------------- training -------------------------------------------\n",
        "history = model.fit(train_ds, validation_data = val_ds, epochs = 5)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "282/282 [==============================] - 1304s 5s/step - loss: 2.9650 - accuracy: 0.4579 - val_loss: 1.1862 - val_accuracy: 0.6016\n",
            "Epoch 2/5\n",
            "282/282 [==============================] - 1291s 5s/step - loss: 0.6000 - accuracy: 0.8021 - val_loss: 1.1848 - val_accuracy: 0.6276\n",
            "Epoch 3/5\n",
            "282/282 [==============================] - 1311s 5s/step - loss: 0.1994 - accuracy: 0.9453 - val_loss: 1.2801 - val_accuracy: 0.6286\n",
            "Epoch 4/5\n",
            "282/282 [==============================] - 1313s 5s/step - loss: 0.0654 - accuracy: 0.9877 - val_loss: 1.3526 - val_accuracy: 0.6416\n",
            "Epoch 5/5\n",
            "282/282 [==============================] - 1317s 5s/step - loss: 0.0234 - accuracy: 0.9982 - val_loss: 1.4368 - val_accuracy: 0.6476\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}