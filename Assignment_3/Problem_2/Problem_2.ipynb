{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Problem_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32a20f4fec2046d48ffbac92190db4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d9dc4d0a916f4c5692fd90381710cd9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69fbcb61745d442ca13e54d54dd550d1",
              "IPY_MODEL_5baaf45b6ea945b990a5f989172d9bcb"
            ]
          }
        },
        "d9dc4d0a916f4c5692fd90381710cd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69fbcb61745d442ca13e54d54dd550d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_49319b79dacc4ba68e4fab3817c85b50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 56.24MB of 56.24MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca4b3509b53c413085d371afcd1e7a1c"
          }
        },
        "5baaf45b6ea945b990a5f989172d9bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba0bd1f2c7864409bb6720c74fea1796",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c76ae60e95014455adae30a8c08f5679"
          }
        },
        "49319b79dacc4ba68e4fab3817c85b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca4b3509b53c413085d371afcd1e7a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba0bd1f2c7864409bb6720c74fea1796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c76ae60e95014455adae30a8c08f5679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZTX7iHiPQXT"
      },
      "source": [
        "**IMPORT REQUIRED LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OlH8H6Dgseh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import pathlib\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2owBTh1XPWuP"
      },
      "source": [
        "**CONNECTING TO WANDB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crwiwHucLS08",
        "outputId": "da917387-0aaa-4543-b9fe-3b387744c54a"
      },
      "source": [
        "# #---------------------------------------install and import wandb -------------------------------------------------\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1MB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 38.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 37.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egDsuCfTLWzv",
        "outputId": "db5aa8b3-e798-4f4a-c8e7-2fabf69f8efb"
      },
      "source": [
        "# #--------------------------------------------login to wandb --------------------------------------------\n",
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STMGDOBCguDe",
        "outputId": "81aa82aa-e230-48d1-dbb7-96fbcee7d046"
      },
      "source": [
        "#--------------------------------caution: terminal commands ---------------------------------------------\n",
        "%cd\n",
        "%cd .keras/datasets/\n",
        "!rm -r *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "[Errno 2] No such file or directory: '.keras/datasets/'\n",
            "/root\n",
            "rm: cannot remove '*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kExxbfhyguAW",
        "outputId": "10de5577-e4fd-4dba-c9de-792fef04dceb"
      },
      "source": [
        "########################################### download data from given url ###############################################\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "data_dir = tf.keras.utils.get_file('dakshina_dataset_v1.0', origin=dataset_url, untar=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "2008342528/2008340480 [==============================] - 19s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsOhKufxgt7-",
        "outputId": "bc846ee9-b1d5-4da3-fe62-2a97da1a6f17"
      },
      "source": [
        "#----------------------------------terminal command -----------------------------------------------\n",
        "%cd /root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons\n",
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxSiYbw8hpcH"
      },
      "source": [
        "train_data_path = \"hi.translit.sampled.train.tsv\"\n",
        "test_data_path = \"hi.translit.sampled.test.tsv\"\n",
        "validation_data_path = \"hi.translit.sampled.dev.tsv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ihHzaQ5KXj_"
      },
      "source": [
        "**UTILITY FUNCTIONS FOR PREPOCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iqFHMS9Msbd"
      },
      "source": [
        "################################# function for vectorizing the data ##########################################\n",
        "\n",
        "def vectorize_data(train_data_path):\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "  with open(train_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "  for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    #---------------We use \"tab\" as the \"start sequence\" character---------------------\n",
        "    #----------------for the targets, and \"\\n\" as \"end sequence\" character-----------------.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "  #--------------------------------artificially added-----------------------------\n",
        "  input_characters.add(\" \")\n",
        "  target_characters.add(\" \")\n",
        "\n",
        "  input_characters = sorted(list(input_characters))\n",
        "  target_characters = sorted(list(target_characters))\n",
        "\n",
        "  num_encoder_tokens = len(input_characters)\n",
        "  num_decoder_tokens = len(target_characters)\n",
        "  max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "  max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "  print(\"Number of samples:\", len(input_texts))\n",
        "  print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "  print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "  print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "  print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "  input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "  target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "  input_details = [input_characters, input_texts, input_token_index, num_encoder_tokens, max_encoder_seq_length]\n",
        "  target_details = [target_characters, target_texts, target_token_index, num_decoder_tokens, max_decoder_seq_length]\n",
        "\n",
        "  return (input_details, target_details)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK_dT-20VMk1"
      },
      "source": [
        "################### function for converting the data into apropriate ONE-Hot vector ######################\n",
        "\n",
        "def onehot(input_details, target_details):\n",
        "\n",
        "    #---------------------------unzipping information-----------------------------------\n",
        "    input_characters = input_details[0]\n",
        "    input_texts = input_details[1]\n",
        "    input_token_index = input_details[2]\n",
        "    num_encoder_tokens = input_details[3]\n",
        "    max_encoder_seq_length = input_details[4]\n",
        "\n",
        "    target_characters = target_details[0]\n",
        "    target_texts = target_details[1]\n",
        "    target_token_index = target_details[2]\n",
        "    num_decoder_tokens = target_details[3]\n",
        "    max_decoder_seq_length = target_details[4]\n",
        "\n",
        "    #---------------------------- creating 3-Dim  matrics with all entries = 0 ----------------------------------- \n",
        "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
        "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "\n",
        "        encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "        for t, char in enumerate(target_text):\n",
        "# --------------decoder_target_data is ahead of decoder_input_data by one timestep ----------------------------\n",
        "            decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "            \n",
        "            if t > 0:\n",
        "# ----------------decoder_target_data will be ahead by one timestep----------------------------------\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "\n",
        "        decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "        decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "    \n",
        "    return (encoder_input_data, decoder_input_data, decoder_target_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es6uD_3JJT7p"
      },
      "source": [
        "################### function for creating data into appropriate form required for embedding ###################\n",
        "\n",
        "def get_input_for_embedding(input_details, embed_size, train_details = None):\n",
        "\n",
        "  #---------------------------unzipping information-----------------------------------\n",
        "  # print(\"\\n input_details \\n\",input_details)\n",
        "  input_characters = input_details[0]\n",
        "  input_texts = input_details[1]\n",
        "  input_token_index = input_details[2]\n",
        "  num_encoder_tokens = input_details[3]\n",
        "  max_encoder_seq_length = input_details[4]\n",
        "\n",
        "  if train_details != None:\n",
        "    # print(\"validation\")\n",
        "    input_token_index = train_details[2]\n",
        "  \n",
        "  input_array = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
        "  for (i, input_text) in enumerate(input_texts):\n",
        "        for (t, char) in enumerate(input_text):\n",
        "          input_array[i, t] = input_token_index[\" \"]\n",
        "          if char in input_token_index:\n",
        "            input_array[i, t] = input_token_index[char]\n",
        "        input_array[i, t + 1 :] = input_token_index[\" \"]\n",
        "\n",
        "  # print(\"input array\",input_array)\n",
        "  return input_array\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N82OZs3TNcLK"
      },
      "source": [
        "\n",
        "**MACHINE TRANSLITERATOR**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYsd6Xetg7dv"
      },
      "source": [
        "class Machine_Transliterator():\n",
        "\n",
        "  ############################################# constructor for class Machine_Transliterator ##########################################\n",
        "\n",
        "  def __init__(self,max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, decoder_embed_size,\n",
        "               num_encoder_layers,num_decoder_layers,epochs, hidden_layer_size,\n",
        "               num_encoder_tokens, cell_type, num_decoder_tokens,input_token_index, target_token_index, \n",
        "               activation=\"softmax\",optimizer=\"rmsprop\",dropout=0.5):\n",
        "    \n",
        "    self.cell_type= cell_type\n",
        "    self.hidden_layer_size = hidden_layer_size  \n",
        "    self.optimizer = optimizer\n",
        "    self.activation = activation   \n",
        "    self.dropout=dropout\n",
        "\n",
        "    #-------------------------------------- Number of hidden layers -------------------------------------\n",
        "\n",
        "    self.num_encoder_layers = num_encoder_layers\n",
        "    self.num_decoder_layers=num_decoder_layers\n",
        "\n",
        "    #-------------------------------------- sequence length -------------------------------------\n",
        "    self.max_decoder_seq_length=max_decoder_seq_length\n",
        "    self.max_encoder_seq_length=max_encoder_seq_length\n",
        "\n",
        "    #---------------------------------------------Embedding size-------------------------------------\n",
        "    self.encoder_embed_size = encoder_embed_size\n",
        "    self.decoder_embed_size = decoder_embed_size\n",
        "    \n",
        "    #-----------------information obtained after preprocessing of data-------------------------------------\n",
        "    self.num_encoder_tokens = num_encoder_tokens\n",
        "    self.num_decoder_tokens = num_decoder_tokens\n",
        "\n",
        "    #-----------------------------dictionaries----------------------------------------------------\n",
        "    self.input_token_index = input_token_index\n",
        "    self.target_token_index = target_token_index\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "#########################################function to build model ###########################################\n",
        "\n",
        "  def build_model(self):\n",
        "\n",
        "    \n",
        "    encoder_inputs = keras.Input(shape=(None,))   \n",
        "    encoder_embedding_output = tf.keras.layers.Embedding(self.num_encoder_tokens, self.encoder_embed_size)(encoder_inputs)\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = LSTM -------------------------------------------------------------\n",
        "    if self.cell_type == \"lstm\":\n",
        "     #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True)\n",
        "      encoder_outputs, state_h, state_c = encoder(encoder_embedding_output)\n",
        "      for i in range(1,self.num_encoder_layers):\n",
        "        encoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True)\n",
        "        encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "      encoder_states = [state_h, state_c]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None, ))      \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(self.num_decoder_tokens, self.decoder_embed_size)(decoder_inputs)\n",
        "\n",
        "      decoder = keras.layers.LSTM(self.hidden_layer_size, return_sequences=True, return_state=True,dropout=self.dropout,use_bias=True)\n",
        "      decoder_outputs, _, _= decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "      for i in range(1,self.num_decoder_layers):\n",
        "        decoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True)\n",
        "        decoder_outputs, _ , _= decoder(decoder_outputs, initial_state = encoder_states)\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = Simple RNN -------------------------------------------------------------\n",
        "    elif self.cell_type == \"rnn\":\n",
        "      #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout, use_bias=True)\n",
        "      encoder_outputs, state = encoder(encoder_embedding_output)\n",
        "      for i in range(1,self.num_encoder_layers):\n",
        "        encoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout, use_bias=True)\n",
        "        encoder_outputs, state = encoder(encoder_outputs)\n",
        "      encoder_states = [state]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None,))      \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(self.num_decoder_tokens, self.decoder_embed_size)(decoder_inputs)\n",
        "\n",
        "      decoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout, use_bias=True)\n",
        "      decoder_outputs, _ = decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "      for i in range(1,self.num_decoder_layers):\n",
        "        decoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout, use_bias=True)\n",
        "        decoder_outputs, _= decoder(decoder_outputs, initial_state = encoder_states)\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = GRU -------------------------------------------------------------\n",
        "    elif self.cell_type == \"gru\":\n",
        "      #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True)\n",
        "      encoder_outputs, state = encoder(encoder_embedding_output)\n",
        "      for i in range(1,self.num_encoder_layers):\n",
        "        encoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True)\n",
        "        encoder_outputs, state = encoder(encoder_outputs)\n",
        "      encoder_states = [state]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None, ))      \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(self.num_decoder_tokens, self.decoder_embed_size)(decoder_inputs)\n",
        "      \n",
        "      decoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout,use_bias=True)\n",
        "      decoder_outputs, _ = decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "      for i in range(1,self.num_decoder_layers):\n",
        "        decoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True)\n",
        "        decoder_outputs, _ = decoder(decoder_outputs, initial_state = encoder_states)\n",
        "\n",
        "\n",
        "    decoder_dense = keras.layers.Dense(self.num_decoder_tokens, activation = self.activation,use_bias=True)\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "         #-----------------compile the model -------------------------------------\n",
        "    model.compile(\n",
        "         optimizer=self.optimizer,\n",
        "         loss=\"categorical_crossentropy\",\n",
        "         metrics=[\"accuracy\"]\n",
        "         ) \n",
        "\n",
        "#-------------------------- return final model ---------------------------------------------------------\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#########################################function for training the model ###########################################\n",
        "\n",
        "  def train_model(self,encoder_input_data,decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "                  val_encoder_input_data, val_decoder_input_data, val_decoder_target_data):\n",
        "    \n",
        "     model=self.build_model()\n",
        "  \n",
        "     model.fit(\n",
        "        [encoder_input_data, decoder_input_data],\n",
        "        decoder_target_data,\n",
        "        batch_size = batch_size,\n",
        "        epochs = epochs,\n",
        "        validation_data = ([val_encoder_input_data, val_decoder_input_data],val_decoder_target_data), \n",
        "        callbacks=[WandbCallback()]\n",
        "        )\n",
        "     return model\n",
        "\n",
        "#===================================== end of class Machine_Transliterator ==========================================\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR4rOYbMVIUZ"
      },
      "source": [
        "**PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llXj7Z6LSnMz"
      },
      "source": [
        "cell_type = \"gru\" # Type of the recurring unit\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 20  # Number of epochs to train for.\n",
        "hidden_layer_size= 512  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "activation = \"softmax\" #activation\n",
        "optimizer = \"Adam\"  #optimizer\n",
        "encoder_embed_size = 32 #Encoder embedsize\n",
        "decoder_embed_size = 32 #Decoder embedsize\n",
        "num_encoder_layers=3  # number of hidden layers in encoder\n",
        "num_decoder_layers=3   # number of hidden layers in decoder\n",
        "dropout=0.05 #Dropout"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH8MZK3IPERe"
      },
      "source": [
        "**PREPROCESSING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYj3x6F4SNTm",
        "outputId": "9b9f0a10-4a61-43ec-c4b9-7604c648afe1"
      },
      "source": [
        "############################# preprocessing the train data ################################\n",
        "\n",
        "#---------------------------- vectorizing train data ----------------------------------\n",
        "input_details, target_details = vectorize_data(train_data_path)\n",
        "\n",
        "#------------------------converting data into one-hot representation ---------------------------\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = onehot(input_details, target_details)\n",
        "\n",
        "#------------------------------- unzipping the data ----------------------------------------\n",
        "input_characters = input_details[0]\n",
        "input_texts = input_details[1]\n",
        "input_token_index = input_details[2]\n",
        "num_encoder_tokens = input_details[3]\n",
        "max_encoder_seq_length = input_details[4]\n",
        "target_characters = target_details[0]\n",
        "target_texts = target_details[1]\n",
        "target_token_index = target_details[2]\n",
        "num_decoder_tokens = target_details[3]\n",
        "max_decoder_seq_length = target_details[4]\n",
        "\n",
        "#-------------------- converting input data into appropriate embedding ----------------------\n",
        "encoder_input_data = get_input_for_embedding(input_details, encoder_embed_size)\n",
        "decoder_input_data = get_input_for_embedding(target_details, decoder_embed_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 64\n",
            "Max sequence length for inputs: 18\n",
            "Max sequence length for outputs: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2PGYsKfb84-",
        "outputId": "5dab04a1-135d-4512-c879-585f759797cd"
      },
      "source": [
        "############################# preprocessing the validation data ################################\n",
        "\n",
        "#---------------------------- vectorizing validation data ----------------------------------\n",
        "val_input_details, val_target_details = vectorize_data(validation_data_path)\n",
        "\n",
        "#------------------------converting data into one-hot representation ---------------------------\n",
        "val_encoder_input_data, val_decoder_input_data, val_decoder_target_data = onehot(val_input_details, val_target_details)\n",
        "\n",
        "#------------------------------- unzipping the data ----------------------------------------\n",
        "val_input_characters = val_input_details[0]\n",
        "val_input_texts = val_input_details[1]\n",
        "val_input_token_index = val_input_details[2]\n",
        "val_num_encoder_tokens = val_input_details[3]\n",
        "val_max_encoder_seq_length = val_input_details[4]\n",
        "val_target_characters = val_target_details[0]\n",
        "val_target_texts = val_target_details[1]\n",
        "val_target_token_index = val_target_details[2]\n",
        "val_num_decoder_tokens = val_target_details[3]\n",
        "val_max_decoder_seq_length = val_target_details[4]\n",
        "\n",
        "#-------------------- converting input data into appropriate embedding ----------------------\n",
        "val_encoder_input_data = get_input_for_embedding(val_input_details, encoder_embed_size, input_details)\n",
        "val_decoder_input_data = get_input_for_embedding(val_target_details, decoder_embed_size, target_details)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 4358\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 64\n",
            "Max sequence length for inputs: 18\n",
            "Max sequence length for outputs: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWh3rwRTcDuT"
      },
      "source": [
        "**CREATING MACHINE TRANSLITERATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeEXyTYcg7bF"
      },
      "source": [
        "# ########################### creating machine transliterator object ###############################\n",
        "# machine = Machine_Transliterator(\n",
        "#     max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, \n",
        "#     decoder_embed_size,num_encoder_layers,num_decoder_layers,\n",
        "#     batch_size, hidden_layer_size, num_encoder_tokens, cell_type, num_decoder_tokens, \n",
        "#      input_token_index,target_token_index, activation, optimizer,dropout\n",
        "#     )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJlX41fVRs1x"
      },
      "source": [
        "**TRAINING**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UQyh8rmdkM8"
      },
      "source": [
        "# model = machine.train_model(\n",
        "#     encoder_input_data, decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "#     val_encoder_input_data, val_decoder_input_data, val_decoder_target_data\n",
        "#     )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF13lTHNKOoQ"
      },
      "source": [
        "# tf.keras.utils.plot_model(model,to_file='model.png',show_shapes=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGyQpSk4zd0V"
      },
      "source": [
        "cell_type = [\"lstm\",\"rnn\",\"gru\"]\n",
        "batch_size = [16,32,64,128]  # Batch size for training.\n",
        "epochs = [10,20,30,50]  # Number of epochs to train for.\n",
        "hidden_layer_size= [128,256,512]  # Latent dimensionality of the encoding space.\n",
        "activation = \"softmax\"\n",
        "optimizer = \"Adam\"\n",
        "num_hidden_layers=[2,5,10]\n",
        "encoder_embed_size = [27,64] #Encoder embedsize\n",
        "decoder_embed_size = [27,64] #Decoder embedsize\n",
        "num_encoder_layers=[1,2,3,4]  # number of hidden layers in encoder\n",
        "num_decoder_layers=[1,2,3,4]    # number of hidden layers in decoder\n",
        "dropout=[0.00,0.01, 0.5,0.0001] #Dropout"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F7lOm3MzREt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ff15e7-68c4-4ab2-a575-fb5ae982811c"
      },
      "source": [
        "sweep_config={\n",
        "              \"method\":\"random\",\n",
        "              'metric' : {\n",
        "                            'name' : 'val_accuracy',\n",
        "                            'goal' : 'maximize',\n",
        "                         },\n",
        "          \"parameters\" : {\n",
        "                            \"cell_type\":{\"values\":[\"lstm\",\"rnn\", \"gru\"]},\n",
        "                            \"batch_size\":{\"values\": [32,64,128]},\n",
        "                            \"epochs\":{\"values\":[40,60]}, \n",
        "                            \"hidden_layer_size\":{\"values\": [128,256,512,1024]}, \n",
        "                            \"num_hidden_layers\": {\"values\": [2,5,10]},\n",
        "                            \"encoder_embed_size\": {\"values\": [27,64] },\n",
        "                            \"decoder_embed_size\": {\"values\":[27,64]  },\n",
        "                            \"num_encoder_layers\": {\"values\": [1,2,3,4]},\n",
        "                            \"num_decoder_layers\":{\"values\":[1,2,3,4] },\n",
        "                            \"dropout\": {\"values\":[0.00,0.01, 0.5,0.0001]}\n",
        "                         }\n",
        "              }\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Machine_Transliterator\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: malfnxb9\n",
            "Sweep URL: https://wandb.ai/anshikag_2210/Machine_Transliterator/sweeps/malfnxb9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkSWJ0evzbNc"
      },
      "source": [
        "def run():\n",
        "\n",
        "  wb = wandb.init()\n",
        "  config = wb.config\n",
        "\n",
        "  #----------------------sweep parameters------------------------------------\n",
        "  cell_type =config.cell_type \n",
        "  batch_size = config.batch_size \n",
        "  epochs = config.epochs \n",
        "  hidden_layer_size= config.hidden_layer_size\n",
        "  encoder_embed_size =config.encoder_embed_size\n",
        "  decoder_embed_size = config.decoder_embed_size\n",
        "  num_encoder_layers=config.num_encoder_layers\n",
        "  num_decoder_layers= config.num_decoder_layers \n",
        "  dropout=config.dropout\n",
        "  \n",
        "  ########################### creating machine transliterator object ###############################\n",
        "  machine = Machine_Transliterator(\n",
        "      max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, \n",
        "      decoder_embed_size,num_encoder_layers,num_decoder_layers,\n",
        "      batch_size, hidden_layer_size, num_encoder_tokens, cell_type, num_decoder_tokens, \n",
        "      input_token_index,target_token_index, activation, optimizer,dropout\n",
        "      )\n",
        "  model = machine.train_model(\n",
        "      encoder_input_data, decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "      val_encoder_input_data, val_decoder_input_data, val_decoder_target_data\n",
        "      )  \n",
        "  return"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "32a20f4fec2046d48ffbac92190db4c3",
            "d9dc4d0a916f4c5692fd90381710cd9a",
            "69fbcb61745d442ca13e54d54dd550d1",
            "5baaf45b6ea945b990a5f989172d9bcb",
            "49319b79dacc4ba68e4fab3817c85b50",
            "ca4b3509b53c413085d371afcd1e7a1c",
            "ba0bd1f2c7864409bb6720c74fea1796",
            "c76ae60e95014455adae30a8c08f5679"
          ]
        },
        "id": "yeoe7fbqOpb9",
        "outputId": "35fce160-2081-4db7-f277-fcde86c4d7c3"
      },
      "source": [
        "wandb.agent(sweep_id, run)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1bt0t9pc with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_embed_size: 27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_embed_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 60\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manshikag_2210\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">youthful-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator/sweeps/malfnxb9\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator/sweeps/malfnxb9</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator/runs/1bt0t9pc\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator/runs/1bt0t9pc</a><br/>\n",
              "                Run data is saved locally in <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210427_123854-1bt0t9pc</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "157/157 [==============================] - 47s 74ms/step - loss: 1.7397 - accuracy: 0.6353 - val_loss: 1.5222 - val_accuracy: 0.6549\n",
            "Epoch 2/60\n",
            "157/157 [==============================] - 10s 63ms/step - loss: 0.9760 - accuracy: 0.7299 - val_loss: 1.4463 - val_accuracy: 0.6750\n",
            "Epoch 3/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.9005 - accuracy: 0.7484 - val_loss: 1.4263 - val_accuracy: 0.6838\n",
            "Epoch 4/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.8333 - accuracy: 0.7631 - val_loss: 1.4271 - val_accuracy: 0.6870\n",
            "Epoch 5/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.7896 - accuracy: 0.7760 - val_loss: 1.4402 - val_accuracy: 0.6963\n",
            "Epoch 6/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.7164 - accuracy: 0.7937 - val_loss: 1.4305 - val_accuracy: 0.7016\n",
            "Epoch 7/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.6193 - accuracy: 0.8184 - val_loss: 1.3463 - val_accuracy: 0.7183\n",
            "Epoch 8/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.4966 - accuracy: 0.8504 - val_loss: 1.3361 - val_accuracy: 0.7217\n",
            "Epoch 9/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.3914 - accuracy: 0.8814 - val_loss: 1.1942 - val_accuracy: 0.7522\n",
            "Epoch 10/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.3004 - accuracy: 0.9092 - val_loss: 1.1949 - val_accuracy: 0.7594\n",
            "Epoch 11/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.2149 - accuracy: 0.9357 - val_loss: 1.1442 - val_accuracy: 0.7683\n",
            "Epoch 12/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.1634 - accuracy: 0.9522 - val_loss: 1.1743 - val_accuracy: 0.7700\n",
            "Epoch 13/60\n",
            "157/157 [==============================] - 10s 63ms/step - loss: 0.1183 - accuracy: 0.9667 - val_loss: 1.1642 - val_accuracy: 0.7736\n",
            "Epoch 14/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0903 - accuracy: 0.9747 - val_loss: 1.1446 - val_accuracy: 0.7867\n",
            "Epoch 15/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0691 - accuracy: 0.9813 - val_loss: 1.1885 - val_accuracy: 0.7793\n",
            "Epoch 16/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0517 - accuracy: 0.9863 - val_loss: 1.2050 - val_accuracy: 0.7844\n",
            "Epoch 17/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0415 - accuracy: 0.9892 - val_loss: 1.2119 - val_accuracy: 0.7811\n",
            "Epoch 18/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0352 - accuracy: 0.9912 - val_loss: 1.2438 - val_accuracy: 0.7837\n",
            "Epoch 19/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0307 - accuracy: 0.9922 - val_loss: 1.2411 - val_accuracy: 0.7862\n",
            "Epoch 20/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0288 - accuracy: 0.9925 - val_loss: 1.2577 - val_accuracy: 0.7875\n",
            "Epoch 21/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 1.2982 - val_accuracy: 0.7822\n",
            "Epoch 22/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 1.3292 - val_accuracy: 0.7796\n",
            "Epoch 23/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0216 - accuracy: 0.9944 - val_loss: 1.2957 - val_accuracy: 0.7872\n",
            "Epoch 24/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 1.3556 - val_accuracy: 0.7809\n",
            "Epoch 25/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 1.3108 - val_accuracy: 0.7811\n",
            "Epoch 26/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 1.3445 - val_accuracy: 0.7865\n",
            "Epoch 27/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 1.3391 - val_accuracy: 0.7853\n",
            "Epoch 28/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 1.3691 - val_accuracy: 0.7790\n",
            "Epoch 29/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 1.3535 - val_accuracy: 0.7872\n",
            "Epoch 30/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 1.3920 - val_accuracy: 0.7867\n",
            "Epoch 31/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 1.3493 - val_accuracy: 0.7918\n",
            "Epoch 32/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 1.3807 - val_accuracy: 0.7893\n",
            "Epoch 33/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 1.4006 - val_accuracy: 0.7884\n",
            "Epoch 34/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 1.3845 - val_accuracy: 0.7898\n",
            "Epoch 35/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 1.4743 - val_accuracy: 0.7813\n",
            "Epoch 36/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 1.3885 - val_accuracy: 0.7833\n",
            "Epoch 37/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 1.4125 - val_accuracy: 0.7874\n",
            "Epoch 38/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 1.4094 - val_accuracy: 0.7858\n",
            "Epoch 39/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 1.4000 - val_accuracy: 0.7908\n",
            "Epoch 40/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 1.4287 - val_accuracy: 0.7894\n",
            "Epoch 41/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 1.4491 - val_accuracy: 0.7922\n",
            "Epoch 42/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 1.4204 - val_accuracy: 0.7911\n",
            "Epoch 43/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 1.4911 - val_accuracy: 0.7869\n",
            "Epoch 44/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 1.4612 - val_accuracy: 0.7879\n",
            "Epoch 45/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 1.4590 - val_accuracy: 0.7893\n",
            "Epoch 46/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 1.4773 - val_accuracy: 0.7881\n",
            "Epoch 47/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 1.4603 - val_accuracy: 0.7886\n",
            "Epoch 48/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 1.4656 - val_accuracy: 0.7863\n",
            "Epoch 49/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 1.4194 - val_accuracy: 0.7935\n",
            "Epoch 50/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 1.4973 - val_accuracy: 0.7911\n",
            "Epoch 51/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 1.4432 - val_accuracy: 0.7950\n",
            "Epoch 52/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.4943 - val_accuracy: 0.7902\n",
            "Epoch 53/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 1.4596 - val_accuracy: 0.7961\n",
            "Epoch 54/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.4804 - val_accuracy: 0.7915\n",
            "Epoch 55/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 1.5067 - val_accuracy: 0.7898\n",
            "Epoch 56/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 1.5018 - val_accuracy: 0.7874\n",
            "Epoch 57/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 1.4995 - val_accuracy: 0.7913\n",
            "Epoch 58/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 1.4601 - val_accuracy: 0.7875\n",
            "Epoch 59/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 1.5368 - val_accuracy: 0.7853\n",
            "Epoch 60/60\n",
            "157/157 [==============================] - 10s 62ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 1.5272 - val_accuracy: 0.7884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 163<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32a20f4fec2046d48ffbac92190db4c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 56.23MB of 56.23MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210427_123854-1bt0t9pc/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210427_123854-1bt0t9pc/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>59</td></tr><tr><td>loss</td><td>0.02215</td></tr><tr><td>accuracy</td><td>0.99287</td></tr><tr><td>val_loss</td><td>1.52724</td></tr><tr><td>val_accuracy</td><td>0.78839</td></tr><tr><td>_runtime</td><td>633</td></tr><tr><td>_timestamp</td><td>1619527767</td></tr><tr><td>_step</td><td>59</td></tr><tr><td>best_val_loss</td><td>1.14417</td></tr><tr><td>best_epoch</td><td>10</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▂▃▃▄▅▆▇▇███████████████████████████████</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▂▁▁▁▂▂▃▃▄▄▄▅▅▅▅▅▅▇▆▆▆▇▇▇▇▇▆▇▇▇██▇█</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▄▄▆▇▇█▇▇██▇█▇█▇████▇█▇██████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">youthful-sweep-1</strong>: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator/runs/1bt0t9pc\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator/runs/1bt0t9pc</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j1e5mtdv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_embed_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_embed_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_hidden_layers: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">volcanic-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator/sweeps/malfnxb9\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator/sweeps/malfnxb9</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/anshikag_2210/Machine_Transliterator/runs/j1e5mtdv\" target=\"_blank\">https://wandb.ai/anshikag_2210/Machine_Transliterator/runs/j1e5mtdv</a><br/>\n",
              "                Run data is saved locally in <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210427_124937-j1e5mtdv</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "157/157 [==============================] - 53s 265ms/step - loss: 1.8545 - accuracy: 0.6451 - val_loss: 1.4684 - val_accuracy: 0.6584\n",
            "Epoch 2/40\n",
            "157/157 [==============================] - 39s 251ms/step - loss: 0.9766 - accuracy: 0.7283 - val_loss: 1.4019 - val_accuracy: 0.6723\n",
            "Epoch 3/40\n",
            "157/157 [==============================] - 39s 250ms/step - loss: 0.8764 - accuracy: 0.7489 - val_loss: 1.3679 - val_accuracy: 0.6852\n",
            "Epoch 4/40\n",
            " 68/157 [===========>..................] - ETA: 19s - loss: 0.7847 - accuracy: 0.7700"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}