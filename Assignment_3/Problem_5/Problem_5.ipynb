{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Problem_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d9c011219374b19a6bdae8d198ae7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_413a18fe17e24b4d9e7d1a62c9ea4db7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d86a099d7e4b4e62b210d61406444759",
              "IPY_MODEL_18dbd92d2dbc45aeb14c9778dfc24677"
            ]
          }
        },
        "413a18fe17e24b4d9e7d1a62c9ea4db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d86a099d7e4b4e62b210d61406444759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_2441cdb63d3b4282b4c36054b1b23e51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7.67MB of 7.67MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aed627a0b4e040bbb2c6147561f4fda0"
          }
        },
        "18dbd92d2dbc45aeb14c9778dfc24677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ac4120e55edf499bb31cad2f6624c89b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_959bd19607a34b789eb085187b09c639"
          }
        },
        "2441cdb63d3b4282b4c36054b1b23e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aed627a0b4e040bbb2c6147561f4fda0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac4120e55edf499bb31cad2f6624c89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "959bd19607a34b789eb085187b09c639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b277e5c96ff45298ee5ab191b8da8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eef520e40ae94472b4f7a8443c5f6a0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e3f5d3069894f659815f174f1813bac",
              "IPY_MODEL_2eed75d73f8c4daa8390b5b17e72dedc"
            ]
          }
        },
        "eef520e40ae94472b4f7a8443c5f6a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e3f5d3069894f659815f174f1813bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_ff4295ba4d194c20a34ad2b727e93002",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16.52MB of 16.52MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2883790236b4b57ba1499f79b67039a"
          }
        },
        "2eed75d73f8c4daa8390b5b17e72dedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d6e2f8ad9a564f949e903001a9c8c4be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cc6a400d3194a528956c0002e9c00c1"
          }
        },
        "ff4295ba4d194c20a34ad2b727e93002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2883790236b4b57ba1499f79b67039a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6e2f8ad9a564f949e903001a9c8c4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cc6a400d3194a528956c0002e9c00c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omudKD1bIXeu"
      },
      "source": [
        "**IMPORT STATEMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OlH8H6Dgseh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Input, GRU, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import pathlib\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd8ZSfS7Jjf8",
        "outputId": "194dfa99-b984-4595-be30-326faea0fb96"
      },
      "source": [
        "#---------------------------------------install and import wandb -------------------------------------------------\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 4.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 10.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 37.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP1BSoKiJqIs",
        "outputId": "d48ad961-1d7d-4f0f-d9dc-afd32788e401"
      },
      "source": [
        "# --------------------------------------------login to wandb --------------------------------------------\n",
        "!wandb login"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STMGDOBCguDe",
        "outputId": "de5313ed-66f1-48fa-aa33-72c0e377d526"
      },
      "source": [
        "#--------------------------------caution: terminal commands ---------------------------------------------\n",
        "%cd\n",
        "%cd .keras/datasets/\n",
        "!rm -r *"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "[Errno 2] No such file or directory: '.keras/datasets/'\n",
            "/root\n",
            "rm: cannot remove '*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kExxbfhyguAW",
        "outputId": "4087bede-79ef-4b7a-a951-bbd12096f08a"
      },
      "source": [
        "########################################### download data from given url ###############################################\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "data_dir = tf.keras.utils.get_file('dakshina_dataset_v1.0', origin=dataset_url, untar=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "2008342528/2008340480 [==============================] - 23s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsOhKufxgt7-",
        "outputId": "a574dbd6-0383-4b60-a4a2-c0a66bced426"
      },
      "source": [
        "#----------------------------------terminal command -----------------------------------------------\n",
        "%cd /root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons\n",
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxSiYbw8hpcH"
      },
      "source": [
        "train_data_path = \"hi.translit.sampled.train.tsv\"\n",
        "test_data_path = \"hi.translit.sampled.test.tsv\"\n",
        "validation_data_path = \"hi.translit.sampled.dev.tsv\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtQd8WIJjcfi"
      },
      "source": [
        "**UTILITY FUNCTION FOR DATA PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmc0tpmjjbE3"
      },
      "source": [
        "################################################ preparing the data in required format #################################################\n",
        "\n",
        "def data(path,input_token_index,target_token_index):\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "      lines = f.read().split(\"\\n\")\n",
        "  del lines[-1]\n",
        "  for line in lines:\n",
        "      target_text, input_text, _ = line.split(\"\\t\")\n",
        "\n",
        "      input_text = \"\\t\"+input_text + \"\\n\"\n",
        "      target_text = \"\\t\"+target_text + \"\\n\"\n",
        "\n",
        "      input_texts.append(input_text)\n",
        "      target_texts.append(target_text)\n",
        "\n",
        "  encoder_input_data = np.zeros( (len(input_texts), max_encoder_seq_length), dtype=\"int32\")\n",
        "  decoder_input_data = np.zeros( (len(input_texts), max_decoder_seq_length), dtype=\"int32\")\n",
        "  decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"int32\")\n",
        "\n",
        "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "      for t, char in enumerate(input_text):\n",
        "          encoder_input_data[i, t] = input_token_index[char]\n",
        "      encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "      for t, char in enumerate(target_text):\n",
        "          # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "          decoder_input_data[i, t] = target_token_index[char]\n",
        "          if t > 0:\n",
        "              # decoder_target_data will be ahead by one timestep\n",
        "              # and will not include the start character.\n",
        "              decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "      decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "      decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "    \n",
        "  return (encoder_input_data, decoder_input_data, decoder_target_data, target_texts, input_texts)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHX43bsSjPZ0"
      },
      "source": [
        "**PREPROCESSING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvzlQKeQg481",
        "outputId": "40efe8ab-dd44-4369-c7de-d4b02139a959"
      },
      "source": [
        "################################################ preprocessing the train data and getting dictionaries #################################################\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(train_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "del lines[-1]\n",
        "for line in lines:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    input_text = \"\\t\"+input_text + \"\\n\"\n",
        "    target_text = \"\\t\"+target_text + \"\\n\"\n",
        "\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters.add(\" \")\n",
        "target_characters.add(\" \")\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 44204\n",
            "Number of unique input tokens: 29\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 22\n",
            "Max sequence length for outputs: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdllRZOZDD6h"
      },
      "source": [
        "**CUSTOM ATTENTION LAYER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlF87sMyY7gB"
      },
      "source": [
        "class AttentionLayer(Layer):\n",
        "\n",
        "    ############################################# constructor for class AttentionLayer ##########################################\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    #########################################  Function to build ########################################################\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "\n",
        "        #-------------------------------------- Create a trainable weight variable for this layer-------------------------------------- \n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape) \n",
        "\n",
        "\n",
        "    #######################################  Function to call #################################\n",
        "    def call(self, inputs, verbose=False):\n",
        "\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        ##############################  Function for Energy Step ##############################\n",
        "        def energy_step(inputs, states):\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            #------------------Some parameters required for shaping tensors----------------\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            #------------------Computing S.Wa where S=[s0, s1, ..., si]--------------------\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            #------------------Computing hj.Ua---------------------------------------------\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            #------------------Computing tanh(S.Wa + hj.Ua)--------------------------------\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            #------------------Computing softmax(va.tanh(S.Wa + hj.Ua))-------------------------------\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        ####################### Step function for computing ci using ei ###############################\n",
        "        def context_step(inputs, states):            \n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  \n",
        "\n",
        "        #-----------------------Computing energy outputs -----------------------------------------------\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        #-----------------------Computing context vectors ----------------------------------------------\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    ############################ Outputs produced by the layer ##########################################\n",
        "    def compute_output_shape(self, input_shape):        \n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N82OZs3TNcLK"
      },
      "source": [
        "\n",
        "**MACHINE TRANSLITERATOR**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYsd6Xetg7dv"
      },
      "source": [
        "\n",
        "class Machine_Transliterator():\n",
        "\n",
        "  ############################################# constructor for class Machine_Transliterator ##########################################\n",
        "\n",
        "  def __init__(self,max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, decoder_embed_size,\n",
        "               num_encoder_layers,num_decoder_layers,epochs, hidden_layer_size,\n",
        "               num_encoder_tokens, cell_type, num_decoder_tokens,input_token_index, target_token_index, \n",
        "               activation=\"softmax\",optimizer=\"rmsprop\",dropout=0.05):\n",
        "    \n",
        "    self.cell_type= cell_type\n",
        "    self.hidden_layer_size = hidden_layer_size  \n",
        "    self.optimizer = optimizer\n",
        "    self.activation = activation   \n",
        "    self.dropout=dropout\n",
        "\n",
        "    #-------------------------------------- Number of hidden layers -------------------------------------\n",
        "\n",
        "    self.num_encoder_layers = num_encoder_layers\n",
        "    self.num_decoder_layers=num_decoder_layers\n",
        "\n",
        "    #-------------------------------------- sequence length -------------------------------------\n",
        "    self.max_decoder_seq_length=max_decoder_seq_length\n",
        "    self.max_encoder_seq_length=max_encoder_seq_length\n",
        "\n",
        "    #---------------------------------------------Embedding size-------------------------------------\n",
        "    self.encoder_embed_size = encoder_embed_size\n",
        "    self.decoder_embed_size = decoder_embed_size\n",
        "    \n",
        "    #-----------------information obtained after preprocessing of data-------------------------------------\n",
        "    self.num_encoder_tokens = num_encoder_tokens\n",
        "    self.num_decoder_tokens = num_decoder_tokens\n",
        "\n",
        "    #-----------------------------dictionaries----------------------------------------------------\n",
        "    self.input_token_index = input_token_index\n",
        "    self.target_token_index = target_token_index\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "#########################################function to build model ###########################################\n",
        "\n",
        "  def build_model(self):\n",
        "    \n",
        "    encoder_inputs = keras.Input(shape=(None,))  \n",
        "    encoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_encoder_tokens, output_dim = self.encoder_embed_size, name = \"encoder_embedding_layer\")(encoder_inputs)\n",
        "\n",
        "#------------------------------ if cell type = LSTM -------------------------------------------------------------\n",
        "    if self.cell_type == \"lstm\":\n",
        "     #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = \"encoder_layer_0\")\n",
        "      encoder_outputs, state_h, state_c = encoder(encoder_embedding_output)\n",
        "      encoder_states = [state_h, state_c]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None, )) \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_decoder_tokens, output_dim = self.decoder_embed_size, name = \"decoder_embedding_layer\")(decoder_inputs)\n",
        "\n",
        "      decoder = keras.layers.LSTM(self.hidden_layer_size, return_sequences=True, return_state=True,dropout=self.dropout,use_bias=True, name = \"decoder_layer_0\")\n",
        "      decoder_outputs, _, _= decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "\n",
        "      attn_layer = AttentionLayer(name='attention_layer')\n",
        "      attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "      decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "#------------------------------ if cell type = Simple RNN -------------------------------------------------------------\n",
        "    elif self.cell_type == \"rnn\":\n",
        "      #--------------------- encoder -----------------------------------\n",
        "      encoder_inputs = keras.Input(shape=(self.max_encoder_seq_length,))\n",
        "      encoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_encoder_tokens, output_dim = self.encoder_embed_size, name = \"encoder_embedding_layer\", input_length=self.max_encoder_seq_length)(encoder_inputs)\n",
        "\n",
        "      encoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout, use_bias=True, name = \"encoder_layer_0\", unroll=True)\n",
        "      encoder_outputs, state = encoder(encoder_embedding_output)\n",
        "      encoder_states = [state]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(self.max_decoder_seq_length, ))\n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_decoder_tokens, output_dim = self.decoder_embed_size, name = \"decoder_embedding_layer\", input_length=self.max_decoder_seq_length)(decoder_inputs)\n",
        "\n",
        "      decoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout, use_bias=True, name = \"decoder_layer_0\", unroll=True)\n",
        "      decoder_outputs, _ = decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "\n",
        "      attn_layer = AttentionLayer(name='attention_layer')\n",
        "      attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "      decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = GRU -------------------------------------------------------------\n",
        "    elif self.cell_type == \"gru\":\n",
        "      #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = \"encoder_layer_0\")\n",
        "      encoder_outputs, state = encoder(encoder_embedding_output)\n",
        "      encoder_states = [state]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None, ))      \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_decoder_tokens, output_dim = self.decoder_embed_size, name = \"decoder_embedding_layer\")(decoder_inputs)\n",
        "      \n",
        "      decoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout,use_bias=True, name = \"decoder_layer_0\")\n",
        "      decoder_outputs, _ = decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "\n",
        "      attn_layer = AttentionLayer(name='attention_layer')\n",
        "      attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "      decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "    decoder_dense = keras.layers.Dense(self.num_decoder_tokens, activation = self.activation,use_bias=True, name = \"dense\")\n",
        "    dense_time = TimeDistributed(decoder_dense, name='time_distributed_layer')\n",
        "    decoder_pred = dense_time(decoder_concat_input)\n",
        "\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_pred)\n",
        "    \n",
        "    #-----------------compile the model -------------------------------------\n",
        "    model.compile(\n",
        "         optimizer=self.optimizer,\n",
        "         loss=\"categorical_crossentropy\",\n",
        "         metrics=[\"accuracy\"]\n",
        "         ) \n",
        "\n",
        "#-------------------------- return final model ---------------------------------------------------------\n",
        "    return model\n",
        "\n",
        "#########################################function for training the model ###########################################\n",
        "\n",
        "  def train_model(self,encoder_input_data,decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "                  val_encoder_input_data, val_decoder_input_data, val_decoder_target_data):\n",
        "    \n",
        "     model=self.build_model()\n",
        "  \n",
        "     model.fit(\n",
        "        [encoder_input_data, decoder_input_data],\n",
        "        decoder_target_data,\n",
        "        batch_size = batch_size,\n",
        "        epochs = epochs,\n",
        "        validation_data = ([val_encoder_input_data, val_decoder_input_data],val_decoder_target_data),\n",
        "        callbacks=[WandbCallback(), EarlyStopping(patience = 5)]\n",
        "        )\n",
        "     return model\n",
        "\n",
        "######################################### function for inference on the model ###########################################\n",
        "  \n",
        "  def sampling_inference(self, model, num_encoder_layers, num_decoder_layers):\n",
        "\n",
        "    encoder_model = None\n",
        "    decoder_model = None\n",
        "    if self.cell_type == \"lstm\":\n",
        "\n",
        "      #-----------------ENCODER----------------------------\n",
        "      e_inputs = model.input[0]\n",
        "      e_embed_layer = model.get_layer(\"encoder_embedding_layer\")\n",
        "      encoder_inputs = e_embed_layer(e_inputs)\n",
        "\n",
        "      encoder_cell = model.get_layer(\"encoder_layer_\" + str(num_encoder_layers-1))\n",
        "      encoder_outputs, state_h_enc, state_c_enc = encoder_cell(encoder_inputs)\n",
        "      encoder_states = [state_h_enc, state_c_enc]\n",
        "\n",
        "      #----------------encoder model-------------------------------\n",
        "      encoder_model = keras.Model(inputs = e_inputs, outputs = [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "      #------------------DECODER------------------------------\n",
        "      decoder_state_input_h = keras.Input(shape=(self.hidden_layer_size,), name=\"input_decoder_h\")\n",
        "      decoder_state_input_c = keras.Input(shape=(self.hidden_layer_size,), name=\"input_decoder_c\")\n",
        "      decoder_hidden_state_input = Input(shape=(22,self.hidden_layer_size))\n",
        "      decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "      d_inputs = model.input[1] #input_2\n",
        "      d_embed_layer = model.get_layer(\"decoder_embedding_layer\")\n",
        "      decoder_inputs = d_embed_layer(d_inputs)\n",
        "\n",
        "      #---------------decoder cell layers---------------------------\n",
        "      decoder_cell = model.get_layer(\"decoder_layer_\" + str(num_decoder_layers-1))\n",
        "      decoder_outputs, state_h_dec, state_c_dec = decoder_cell(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "      decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "      #-------------------------attention inference ------------------\n",
        "      attn_layer = model.get_layer(\"attention_layer\")\n",
        "      attn_inf_out, attn_inf_states = attn_layer([decoder_hidden_state_input, decoder_outputs])\n",
        "\n",
        "      #------------------------concatenation----------------------------\n",
        "      concate = model.get_layer(\"concat_layer\")\n",
        "      decoder_inf_concat = concate([decoder_outputs, attn_inf_out])\n",
        "\n",
        "      #-------A dense softmax layer to get generate probability over the target vocabulary --------------------\n",
        "      time_dist_dense = model.get_layer(\"time_distributed_layer\")\n",
        "      decoder_inf_pred = time_dist_dense(decoder_inf_concat)\n",
        "\n",
        "\n",
        "      decoder_model = keras.Model( \n",
        "                              [d_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "                              [decoder_inf_pred] + [state_h_dec, state_c_dec]\n",
        "                            )\n",
        "    #-------------------------------------if cell type = Simple RNN or GRU---------------------------------------------\n",
        "    elif self.cell_type ==\"rnn\" or self.cell_type ==\"gru\":\n",
        "\n",
        "      #---------------------------ENCODER---------------------------------\n",
        "      e_inputs = model.input[0]\n",
        "      e_embed_layer = model.get_layer(\"encoder_embedding_layer\")\n",
        "      encoder_inputs = e_embed_layer(e_inputs)\n",
        "\n",
        "      encoder_cell = model.get_layer(\"encoder_layer_\" + str(num_encoder_layers-1))\n",
        "      encoder_outputs, state_h_enc = encoder_cell(encoder_inputs)\n",
        "      encoder_states = [state_h_enc]\n",
        "\n",
        "      #----------------------encoder model-------------------------------\n",
        "      encoder_model = keras.Model(inputs = e_inputs, outputs = [encoder_outputs, state_h_enc])\n",
        "\n",
        "      #-------------------------DECODER---------------------------------------------\n",
        "      decoder_state_input_h = keras.Input(shape=(self.hidden_layer_size,), name=\"input_decoder_h\")\n",
        "      decoder_hidden_state_input = Input(shape=(22,self.hidden_layer_size))\n",
        "      decoder_state_inputs = [decoder_state_input_h]\n",
        "\n",
        "      d_inputs = model.input[1] \n",
        "      d_embed_layer = model.get_layer(\"decoder_embedding_layer\")\n",
        "      decoder_inputs = d_embed_layer(d_inputs)\n",
        "\n",
        "      #-------------------------decoder cell layers---------------------------------\n",
        "      decoder_cell = model.get_layer(\"decoder_layer_\" + str(num_decoder_layers-1))\n",
        "      decoder_outputs, state_h_dec = decoder_cell(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "      decoder_states = [state_h_dec]\n",
        "\n",
        "      #-----------------------------attention inference-----------------------------------\n",
        "      attn_layer = model.get_layer(\"attention_layer\")\n",
        "      attn_inf_out, attn_inf_states = attn_layer([decoder_hidden_state_input, decoder_outputs])\n",
        "\n",
        "      #------------------------------concatenation--------------------------------------\n",
        "      concate = model.get_layer(\"concat_layer\")\n",
        "      decoder_inf_concat = concate([decoder_outputs, attn_inf_out])\n",
        "\n",
        "      #----------- A dense softmax layer to get generate probability over the target vocabulary -----------\n",
        "      time_dist_dense = model.get_layer(\"time_distributed_layer\")\n",
        "      decoder_inf_pred = time_dist_dense(decoder_inf_concat)\n",
        "\n",
        "\n",
        "      decoder_model = keras.Model( \n",
        "                              [d_inputs] + [decoder_hidden_state_input, decoder_state_input_h],\n",
        "                              [decoder_inf_pred] + [state_h_dec]\n",
        "                            )\n",
        "      \n",
        "    reverse_input_char_index = dict((i, char) for char, i in self.input_token_index.items())\n",
        "    reverse_target_char_index = dict((i, char) for char, i in self.target_token_index.items())\n",
        "    return (reverse_input_char_index,reverse_target_char_index, encoder_model, decoder_model)\n",
        "\n",
        "##################################################function for decoding input sequence ###########################################\n",
        "\n",
        "  def decode_sequence(self, input_data, encoder_model, decoder_model, max_decoder_seq_length, target_token_index):\n",
        "\n",
        "    num_examples = input_data.shape[0]\n",
        "    max_encoder_seq_length = input_data.shape[0]\n",
        "\n",
        "    #---------------- raw form of predictions to be returned --------------------------------\n",
        "    predicted_output = np.full((num_examples, max_decoder_seq_length), target_token_index[\" \"])\n",
        "\n",
        "    # ------ -----------if cell type=LSTM ---------------------------------\n",
        "    if self.cell_type ==\"lstm\":\n",
        "      e_out, e_h, e_c = encoder_model.predict(input_data[:num_examples,:])\n",
        "      states = [e_h, e_c]      \n",
        "      target_seq = np.zeros((num_examples, 1),dtype=\"int32\")\n",
        "      target_seq[:, 0] = self.target_token_index[\"\\t\"]  \n",
        "\n",
        "    # ------ -----------if cell type= Simple RNN or GRU --------------------\n",
        "    elif self.cell_type == \"rnn\" or self.cell_type ==\"gru\":\n",
        "      e_out, e_h = encoder_model.predict(input_data[:num_examples,:])\n",
        "      states_value = [e_h]\n",
        "      target_seq = np.zeros((num_examples, 1),dtype=\"int32\")\n",
        "      target_seq[:, 0] = self.target_token_index[\"\\t\"]  \n",
        "\n",
        "    for i in range(max_decoder_seq_length):\n",
        "      # ------------------if cell type=LSTM ---------------------------------\n",
        "      if self.cell_type ==\"lstm\":\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        e_h, e_c = h, c\n",
        "      # ------------------if cell type= Simple RNN or GRU --------------------\n",
        "      elif self.cell_type ==\"rnn\" or self.cell_type ==\"gru\":\n",
        "        output_tokens, h = decoder_model.predict([target_seq] + [e_out, e_h])\n",
        "        e_h = h\n",
        "\n",
        "      for j in range(num_examples):\n",
        "        target_seq[j,0] = np.argmax(output_tokens[j, -1, :])\n",
        "        if target_seq[j,0] == target_token_index[\"\\n\"]:\n",
        "          predicted_output[j,i] = target_token_index[\" \"]\n",
        "        else:\n",
        "          predicted_output[j,i] = target_seq[j,0]\n",
        "\n",
        "  #--------------------------- return predictions ------------------------------\n",
        "    return predicted_output\n",
        "  \n",
        "  ################################################## function for calculating accuracy ###########################################\n",
        "\n",
        "  def calculate_accuracy(self, output_corpus, input_data, reverse_target_char_index, encoder_model, decoder_model):\n",
        "    limit = input_data.shape[0]   \n",
        "\n",
        "    #------------------------------ creating vectorised form of true output ------------------------------\n",
        "    true_output = np.full((limit, self.max_decoder_seq_length), self.target_token_index[\" \"])\n",
        "    for row in range(limit):\n",
        "      example = output_corpus[row].replace(\"\\n\",\"\").replace(\"\\t\",\"\")\n",
        "      for col in range(len(example)):\n",
        "        true_output[row][col] = self.target_token_index[example[col]]\n",
        "    \n",
        "    #------------------------------ creating vectorised form of predicted output --------------------------------\n",
        "    predicted_output = self.decode_sequence(input_data, encoder_model, decoder_model, self.max_decoder_seq_length, target_token_index)\n",
        "\n",
        "    #------------------------------ calculating accuracy ------------------------------------\n",
        "    A = true_output\n",
        "    B = predicted_output \n",
        "    accuracy = (np.count_nonzero((A == B).all(1))/A.shape[0])\n",
        "\n",
        "    wandb.log({\"val_acc\":accuracy})\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "#===================================== end of class Machine_Transliterator ==========================================\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR4rOYbMVIUZ"
      },
      "source": [
        "**PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVfaKFT4iGKc"
      },
      "source": [
        "cell_type = \"rnn\"\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 1  # Number of epochs to train for.\n",
        "hidden_layer_size= 512  # Latent dimensionality of the encoding space.\n",
        "activation = \"softmax\"\n",
        "optimizer = \"Adam\"\n",
        "encoder_embed_size = 256 #Encoder embedsize\n",
        "decoder_embed_size = 256 #Decoder embedsize\n",
        "num_encoder_layers= 1  # number of hidden layers in encoder\n",
        "num_decoder_layers= 1    # number of hidden layers in decoder\n",
        "dropout=0.5 #Dropout"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH8MZK3IPERe"
      },
      "source": [
        "**PREPROCESSING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYj3x6F4SNTm"
      },
      "source": [
        "############################# preprocessing the data ################################\n",
        "\n",
        "(encoder_input_data,decoder_input_data,decoder_target_data, _, _)=data(train_data_path,input_token_index,target_token_index)\n",
        "(val_encoder_input_data,val_decoder_input_data,val_decoder_target_data, val_target_texts, val_input_texts)=data(validation_data_path ,input_token_index,target_token_index)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGu0vosaNV4N"
      },
      "source": [
        "(t_encoder_input_data,t_decoder_input_data,t_decoder_target_data, t_target_texts, t_input_texts)=data(test_data_path ,input_token_index,target_token_index)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ksIw3vH3XJ"
      },
      "source": [
        "**CREATING MACHINE TRANSLITERATOR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZhI8e1dH3XK"
      },
      "source": [
        "########################## creating machine transliterator object ###############################\n",
        "# machine = Machine_Transliterator(\n",
        "#       max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, \n",
        "#       decoder_embed_size,num_encoder_layers,num_decoder_layers,\n",
        "#       batch_size, hidden_layer_size, num_encoder_tokens, cell_type, num_decoder_tokens, \n",
        "#       input_token_index,target_token_index, activation, optimizer,dropout\n",
        "#       )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJlX41fVRs1x"
      },
      "source": [
        "**TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UQyh8rmdkM8"
      },
      "source": [
        "# model = machine.train_model(\n",
        "#     encoder_input_data, decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "#     val_encoder_input_data, val_decoder_input_data, val_decoder_target_data\n",
        "#     )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0MrVvYoJxur"
      },
      "source": [
        "# tf.keras.utils.plot_model(model,to_file='model.png',show_shapes=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx3VFFcQZelg"
      },
      "source": [
        "**INFERENCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTk66ncOehIf"
      },
      "source": [
        "# (reverse_input_char_index,reverse_target_char_index, encoder_model, decoder_model) = machine.sampling_inference(model, num_encoder_layers, num_decoder_layers)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwmLiNZtZjBU"
      },
      "source": [
        "**VALIDATION ACCURACY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmqgC5XcbqdD"
      },
      "source": [
        "# ########################## accuracy calculation ###############################\n",
        "# input_data = val_encoder_input_data #english vectors\n",
        "# output_corpus = val_target_texts #hindi words\n",
        "# val_acc = machine.calculate_accuracy(output_corpus, input_data, reverse_target_char_index, encoder_model, decoder_model)\n",
        "# print(val_acc)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F7lOm3MzREt",
        "outputId": "c90f0372-b1a7-4bc5-e72e-49b3556aef81"
      },
      "source": [
        "optimizer = \"Adam\"\n",
        "activation = \"softmax\"\n",
        "num_encoder_layers=1\n",
        "num_decoder_layers=1\n",
        "\n",
        "sweep_config={\n",
        "              \"method\":\"random\",\n",
        "              'metric' : {\n",
        "                            'name' : 'val_acc',\n",
        "                            'goal' : 'maximize',\n",
        "                         },\n",
        "          \"parameters\" : {\n",
        "                            \"cell_type\":{\"values\":[\"rnn\",\"lstm\",\"gru\"]},\n",
        "                            \"batch_size\":{\"values\": [32,64,128]},\n",
        "                            \"epochs\":{\"values\":[20,25,30,40,60]}, \n",
        "                            \"hidden_layer_size\":{\"values\": [128,256,512,1024,2048]}, \n",
        "                            \"encoder_embed_size\": {\"values\": [27, 64, 128, 512, 1024] },\n",
        "                            \"decoder_embed_size\": {\"values\":[27, 64, 128, 512, 1024]  },\n",
        "                            \"dropout\": {\"values\":[0.00,0.1, 0.05,0.001]}\n",
        "                         }\n",
        "              }\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"NMT\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: hgm7iw7v\n",
            "Sweep URL: https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkSWJ0evzbNc"
      },
      "source": [
        "def run():\n",
        "\n",
        "  wb = wandb.init()\n",
        "  config = wb.config\n",
        "\n",
        "  #----------------------sweep parameters------------------------------------\n",
        "  cell_type =config.cell_type \n",
        "  batch_size = config.batch_size \n",
        "  epochs = config.epochs \n",
        "  hidden_layer_size= config.hidden_layer_size\n",
        "  encoder_embed_size =config.encoder_embed_size\n",
        "  decoder_embed_size = config.decoder_embed_size\n",
        "  dropout=config.dropout\n",
        "  \n",
        "  ########################### creating machine transliterator object ###############################\n",
        "  machine = Machine_Transliterator(\n",
        "      max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, \n",
        "      decoder_embed_size,num_encoder_layers,num_decoder_layers,\n",
        "      batch_size, hidden_layer_size, num_encoder_tokens, cell_type, num_decoder_tokens, \n",
        "      input_token_index,target_token_index, activation, optimizer,dropout\n",
        "      )\n",
        "  model = machine.train_model(\n",
        "      encoder_input_data, decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "      val_encoder_input_data, val_decoder_input_data, val_decoder_target_data\n",
        "      ) \n",
        "  (reverse_input_char_index,reverse_target_char_index, encoder_model, decoder_model) = machine.sampling_inference(model, num_encoder_layers, num_decoder_layers)\n",
        "  val_acc = machine.calculate_accuracy(val_target_texts, val_encoder_input_data, reverse_target_char_index, encoder_model, decoder_model)\n",
        "  return"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8d9c011219374b19a6bdae8d198ae7f4",
            "413a18fe17e24b4d9e7d1a62c9ea4db7",
            "d86a099d7e4b4e62b210d61406444759",
            "18dbd92d2dbc45aeb14c9778dfc24677",
            "2441cdb63d3b4282b4c36054b1b23e51",
            "aed627a0b4e040bbb2c6147561f4fda0",
            "ac4120e55edf499bb31cad2f6624c89b",
            "959bd19607a34b789eb085187b09c639",
            "8b277e5c96ff45298ee5ab191b8da8a6",
            "eef520e40ae94472b4f7a8443c5f6a0e",
            "9e3f5d3069894f659815f174f1813bac",
            "2eed75d73f8c4daa8390b5b17e72dedc",
            "ff4295ba4d194c20a34ad2b727e93002",
            "c2883790236b4b57ba1499f79b67039a",
            "d6e2f8ad9a564f949e903001a9c8c4be",
            "5cc6a400d3194a528956c0002e9c00c1"
          ]
        },
        "id": "yeoe7fbqOpb9",
        "outputId": "28a26f59-aa9c-4de9-9d7b-a1e9c4da7c37"
      },
      "source": [
        "wandb.agent(sweep_id, run, count=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t48f09nk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_embed_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_embed_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manshikag_2210\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">genial-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/anshikag_2210/NMT\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/anshikag_2210/NMT/runs/t48f09nk\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/runs/t48f09nk</a><br/>\n",
              "                Run data is saved locally in <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_142942-t48f09nk</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1382/1382 [==============================] - 165s 95ms/step - loss: 0.9107 - accuracy: 0.7752 - val_loss: 0.2078 - val_accuracy: 0.9359\n",
            "Epoch 2/25\n",
            "1382/1382 [==============================] - 131s 95ms/step - loss: 0.1905 - accuracy: 0.9391 - val_loss: 0.1607 - val_accuracy: 0.9483\n",
            "Epoch 3/25\n",
            "1382/1382 [==============================] - 132s 95ms/step - loss: 0.1489 - accuracy: 0.9520 - val_loss: 0.1482 - val_accuracy: 0.9518\n",
            "Epoch 4/25\n",
            "1382/1382 [==============================] - 131s 95ms/step - loss: 0.1290 - accuracy: 0.9582 - val_loss: 0.1433 - val_accuracy: 0.9535\n",
            "Epoch 5/25\n",
            "1382/1382 [==============================] - 132s 95ms/step - loss: 0.1179 - accuracy: 0.9619 - val_loss: 0.1384 - val_accuracy: 0.9553\n",
            "Epoch 6/25\n",
            "1382/1382 [==============================] - 131s 95ms/step - loss: 0.1089 - accuracy: 0.9650 - val_loss: 0.1355 - val_accuracy: 0.9568\n",
            "Epoch 7/25\n",
            "1382/1382 [==============================] - 131s 95ms/step - loss: 0.1014 - accuracy: 0.9672 - val_loss: 0.1362 - val_accuracy: 0.9569\n",
            "Epoch 8/25\n",
            "1382/1382 [==============================] - 132s 96ms/step - loss: 0.0948 - accuracy: 0.9691 - val_loss: 0.1369 - val_accuracy: 0.9566\n",
            "Epoch 9/25\n",
            "1382/1382 [==============================] - 132s 96ms/step - loss: 0.0903 - accuracy: 0.9706 - val_loss: 0.1369 - val_accuracy: 0.9571\n",
            "Epoch 10/25\n",
            "1382/1382 [==============================] - 133s 96ms/step - loss: 0.0837 - accuracy: 0.9726 - val_loss: 0.1378 - val_accuracy: 0.9570\n",
            "Epoch 11/25\n",
            "1382/1382 [==============================] - 132s 95ms/step - loss: 0.0794 - accuracy: 0.9742 - val_loss: 0.1400 - val_accuracy: 0.9568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 154<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d9c011219374b19a6bdae8d198ae7f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 7.66MB of 7.66MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_142942-t48f09nk/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_142942-t48f09nk/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.08163</td></tr><tr><td>accuracy</td><td>0.97337</td></tr><tr><td>val_loss</td><td>0.14003</td></tr><tr><td>val_accuracy</td><td>0.95675</td></tr><tr><td>_runtime</td><td>1503</td></tr><tr><td>_timestamp</td><td>1621522485</td></tr><tr><td>_step</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.13546</td></tr><tr><td>best_epoch</td><td>5</td></tr><tr><td>val_acc</td><td>0.39123</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▆▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇██████</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▄▅▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▄▅▆▇▇██</td></tr><tr><td>_step</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-1</strong>: <a href=\"https://wandb.ai/anshikag_2210/NMT/runs/t48f09nk\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/runs/t48f09nk</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wczp2wxt with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_embed_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_embed_size: 27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 40\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dazzling-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/anshikag_2210/NMT\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/anshikag_2210/NMT/runs/wczp2wxt\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/runs/wczp2wxt</a><br/>\n",
              "                Run data is saved locally in <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_145453-wczp2wxt</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1382/1382 [==============================] - 152s 106ms/step - loss: 0.9753 - accuracy: 0.7524 - val_loss: 0.2396 - val_accuracy: 0.9284\n",
            "Epoch 2/40\n",
            "1382/1382 [==============================] - 146s 106ms/step - loss: 0.1956 - accuracy: 0.9404 - val_loss: 0.1631 - val_accuracy: 0.9489\n",
            "Epoch 3/40\n",
            "1382/1382 [==============================] - 143s 103ms/step - loss: 0.1358 - accuracy: 0.9571 - val_loss: 0.1499 - val_accuracy: 0.9519\n",
            "Epoch 4/40\n",
            "1382/1382 [==============================] - 145s 105ms/step - loss: 0.1127 - accuracy: 0.9639 - val_loss: 0.1414 - val_accuracy: 0.9551\n",
            "Epoch 5/40\n",
            "1382/1382 [==============================] - 144s 104ms/step - loss: 0.0968 - accuracy: 0.9687 - val_loss: 0.1412 - val_accuracy: 0.9559\n",
            "Epoch 6/40\n",
            "1382/1382 [==============================] - 145s 105ms/step - loss: 0.0837 - accuracy: 0.9728 - val_loss: 0.1398 - val_accuracy: 0.9568\n",
            "Epoch 7/40\n",
            "1382/1382 [==============================] - 145s 105ms/step - loss: 0.0741 - accuracy: 0.9759 - val_loss: 0.1430 - val_accuracy: 0.9565\n",
            "Epoch 8/40\n",
            "1382/1382 [==============================] - 144s 104ms/step - loss: 0.0660 - accuracy: 0.9784 - val_loss: 0.1425 - val_accuracy: 0.9570\n",
            "Epoch 9/40\n",
            "1382/1382 [==============================] - 144s 104ms/step - loss: 0.0595 - accuracy: 0.9805 - val_loss: 0.1466 - val_accuracy: 0.9578\n",
            "Epoch 10/40\n",
            "1382/1382 [==============================] - 144s 105ms/step - loss: 0.0533 - accuracy: 0.9824 - val_loss: 0.1515 - val_accuracy: 0.9566\n",
            "Epoch 11/40\n",
            "1382/1382 [==============================] - 144s 104ms/step - loss: 0.0492 - accuracy: 0.9837 - val_loss: 0.1563 - val_accuracy: 0.9558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 557<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b277e5c96ff45298ee5ab191b8da8a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 16.51MB of 16.51MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_145453-wczp2wxt/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_145453-wczp2wxt/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.05218</td></tr><tr><td>accuracy</td><td>0.98273</td></tr><tr><td>val_loss</td><td>0.15631</td></tr><tr><td>val_accuracy</td><td>0.95581</td></tr><tr><td>_runtime</td><td>1612</td></tr><tr><td>_timestamp</td><td>1621524105</td></tr><tr><td>_step</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.13983</td></tr><tr><td>best_epoch</td><td>5</td></tr><tr><td>val_acc</td><td>0.38114</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>loss</td><td>█▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▆▇▇▇██████</td></tr><tr><td>val_loss</td><td>█▃▂▁▁▁▁▁▁▂▂</td></tr><tr><td>val_accuracy</td><td>▁▆▇▇███████</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▄▅▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▄▅▆▇▇██</td></tr><tr><td>_step</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>val_acc</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">dazzling-sweep-2</strong>: <a href=\"https://wandb.ai/anshikag_2210/NMT/runs/wczp2wxt\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/runs/wczp2wxt</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2l2y77a0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_embed_size: 27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_embed_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 2048\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">smooth-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/anshikag_2210/NMT\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/sweeps/hgm7iw7v</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/anshikag_2210/NMT/runs/2l2y77a0\" target=\"_blank\">https://wandb.ai/anshikag_2210/NMT/runs/2l2y77a0</a><br/>\n",
              "                Run data is saved locally in <code>/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/wandb/run-20210520_152214-2l2y77a0</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            " 402/1382 [=======>......................] - ETA: 7:37 - loss: 1.4560 - accuracy: 0.6740"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}