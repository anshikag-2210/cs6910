{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OlH8H6Dgseh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import cv2\n",
        "import pathlib\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STMGDOBCguDe",
        "outputId": "a562202d-7161-4fd9-ec89-860c9f76a900"
      },
      "source": [
        "#--------------------------------caution: terminal commands ---------------------------------------------\n",
        "%cd\n",
        "%cd .keras/datasets/\n",
        "!rm -r *"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/root/.keras/datasets\n",
            "rm: cannot remove '*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kExxbfhyguAW",
        "outputId": "8991694d-99ea-453a-bdd8-59fa76eac343"
      },
      "source": [
        "########################################### download data from given url ###############################################\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "data_dir = tf.keras.utils.get_file('dakshina_dataset_v1.0', origin=dataset_url, untar=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "2008342528/2008340480 [==============================] - 29s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsOhKufxgt7-",
        "outputId": "6ce9cd08-bd3f-43fa-a4d2-825c3d8a00ff"
      },
      "source": [
        "#----------------------------------terminal command -----------------------------------------------\n",
        "%cd /root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons/\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/dakshina_dataset_v1.0/hi/lexicons\n",
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxSiYbw8hpcH"
      },
      "source": [
        "train_data_path = \"hi.translit.sampled.train.tsv\"\n",
        "test_data_path = \"hi.translit.sampled.test.tsv\"\n",
        "validation_data_path = \"hi.translit.sampled.dev.tsv\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtQd8WIJjcfi"
      },
      "source": [
        "**UTILITY FUNCTION FOR DATA PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmc0tpmjjbE3"
      },
      "source": [
        "################################################ preparing the data in required format #################################################\n",
        "\n",
        "def data(path,input_token_index,target_token_index):\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "      lines = f.read().split(\"\\n\")\n",
        "  del lines[-1]\n",
        "  for line in lines:\n",
        "      target_text, input_text, _ = line.split(\"\\t\")\n",
        "\n",
        "      input_text = \"\\t\"+input_text + \"\\n\"\n",
        "      target_text = \"\\t\"+target_text + \"\\n\"\n",
        "\n",
        "      input_texts.append(input_text)\n",
        "      target_texts.append(target_text)\n",
        "\n",
        "  encoder_input_data = np.zeros( (len(input_texts), max_encoder_seq_length), dtype=\"int32\")\n",
        "  decoder_input_data = np.zeros( (len(input_texts), max_decoder_seq_length), dtype=\"int32\")\n",
        "  decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"int32\")\n",
        "\n",
        "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "      for t, char in enumerate(input_text):\n",
        "          encoder_input_data[i, t] = input_token_index[char]\n",
        "      encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "      for t, char in enumerate(target_text):\n",
        "          # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "          decoder_input_data[i, t] = target_token_index[char]\n",
        "          if t > 0:\n",
        "              # decoder_target_data will be ahead by one timestep\n",
        "              # and will not include the start character.\n",
        "              decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "      decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "      decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "    \n",
        "  return (encoder_input_data, decoder_input_data, decoder_target_data, target_texts, input_texts)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHX43bsSjPZ0"
      },
      "source": [
        "**PREPROCESSING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvzlQKeQg481",
        "outputId": "1f8fa1e5-3331-4528-a0ec-5ffbcc8697ff"
      },
      "source": [
        "################################################ preprocessing the train data and getting dictionaries #################################################\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(train_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "del lines[-1]\n",
        "for line in lines:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    input_text = \"\\t\"+input_text + \"\\n\"\n",
        "    target_text = \"\\t\"+target_text + \"\\n\"\n",
        "\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters.add(\" \")\n",
        "target_characters.add(\" \")\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 44204\n",
            "Number of unique input tokens: 29\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 22\n",
            "Max sequence length for outputs: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N82OZs3TNcLK"
      },
      "source": [
        "\n",
        "**MACHINE TRANSLITERATOR**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYsd6Xetg7dv"
      },
      "source": [
        "class Machine_Transliterator():\n",
        "\n",
        "  ############################################# constructor for class Machine_Transliterator ##########################################\n",
        "\n",
        "  def __init__(self,max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, decoder_embed_size,\n",
        "               num_encoder_layers,num_decoder_layers,epochs, hidden_layer_size,\n",
        "               num_encoder_tokens, cell_type, num_decoder_tokens,input_token_index, target_token_index, \n",
        "               activation=\"softmax\",optimizer=\"rmsprop\",dropout=0.05):\n",
        "    \n",
        "    self.cell_type= cell_type\n",
        "    self.hidden_layer_size = hidden_layer_size  \n",
        "    self.optimizer = optimizer\n",
        "    self.activation = activation   \n",
        "    self.dropout=dropout\n",
        "\n",
        "    #-------------------------------------- Number of hidden layers -------------------------------------\n",
        "\n",
        "    self.num_encoder_layers = num_encoder_layers\n",
        "    self.num_decoder_layers=num_decoder_layers\n",
        "\n",
        "    #-------------------------------------- sequence length -------------------------------------\n",
        "    self.max_decoder_seq_length=max_decoder_seq_length\n",
        "    self.max_encoder_seq_length=max_encoder_seq_length\n",
        "\n",
        "    #---------------------------------------------Embedding size-------------------------------------\n",
        "    self.encoder_embed_size = encoder_embed_size\n",
        "    self.decoder_embed_size = decoder_embed_size\n",
        "    \n",
        "    #-----------------information obtained after preprocessing of data-------------------------------------\n",
        "    self.num_encoder_tokens = num_encoder_tokens\n",
        "    self.num_decoder_tokens = num_decoder_tokens\n",
        "\n",
        "    #-----------------------------dictionaries----------------------------------------------------\n",
        "    self.input_token_index = input_token_index\n",
        "    self.target_token_index = target_token_index\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "########################################## function to build model ###########################################\n",
        "\n",
        "  def build_model(self):\n",
        "\n",
        "    \n",
        "    encoder_inputs = keras.Input(shape=(None,))  \n",
        "    encoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_encoder_tokens, output_dim = self.encoder_embed_size, name = \"encoder_embedding_layer\")(encoder_inputs)\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = LSTM -------------------------------------------------------------\n",
        "    if self.cell_type == \"lstm\":\n",
        "     #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = \"encoder_layer_0\")\n",
        "      encoder_outputs, state_h, state_c = encoder(encoder_embedding_output)\n",
        "      for i in range(1,self.num_encoder_layers):\n",
        "        encoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = (\"encoder_layer_\"+ str(i) ) )\n",
        "        encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "      encoder_states = [state_h, state_c]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None, )) \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_decoder_tokens, output_dim = self.decoder_embed_size, name = \"decoder_embedding_layer\")(decoder_inputs)\n",
        "\n",
        "      decoder = keras.layers.LSTM(self.hidden_layer_size, return_sequences=True, return_state=True,dropout=self.dropout,use_bias=True, name = \"decoder_layer_0\")\n",
        "      decoder_outputs, _, _= decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "      for i in range(1,self.num_decoder_layers):\n",
        "        decoder = keras.layers.LSTM(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = (\"decoder_layer_\"+ str(i) ) )\n",
        "        decoder_outputs, _ , _= decoder(decoder_outputs, initial_state = encoder_states)\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = Simple RNN -------------------------------------------------------------\n",
        "    elif self.cell_type == \"rnn\":\n",
        "      #--------------------- encoder -----------------------------------\n",
        "      encoder_inputs = keras.Input(shape=(self.max_encoder_seq_length,))\n",
        "      encoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_encoder_tokens, output_dim = self.encoder_embed_size, name = \"encoder_embedding_layer\", input_length=self.max_encoder_seq_length)(encoder_inputs)\n",
        "\n",
        "      encoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout, use_bias=True, name = \"encoder_layer_0\", unroll=True)\n",
        "      encoder_outputs, state = encoder(encoder_embedding_output)\n",
        "      for i in range(1,self.num_encoder_layers):\n",
        "        encoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout, use_bias=True, name = (\"encoder_layer_\"+ str(i) ), unroll=True)\n",
        "        encoder_outputs, state = encoder(encoder_outputs)\n",
        "      encoder_states = [state]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(self.max_decoder_seq_length, ))      \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_decoder_tokens, output_dim = self.decoder_embed_size, name = \"decoder_embedding_layer\", input_length=self.max_decoder_seq_length)(decoder_inputs)\n",
        "\n",
        "      decoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout, use_bias=True, name = \"decoder_layer_0\", unroll=True)\n",
        "      decoder_outputs, _ = decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "      for i in range(1,self.num_decoder_layers):\n",
        "        decoder = keras.layers.SimpleRNN(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout, use_bias=True, name = (\"decoder_layer_\"+ str(i) ), unroll=True)\n",
        "        decoder_outputs, _= decoder(decoder_outputs, initial_state = encoder_states)\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------ if cell type = GRU -------------------------------------------------------------\n",
        "    elif self.cell_type == \"gru\":\n",
        "      #--------------------- encoder -----------------------------------\n",
        "      encoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = \"encoder_layer_0\")\n",
        "      encoder_outputs, state = encoder(encoder_embedding_output)\n",
        "      for i in range(1,self.num_encoder_layers):\n",
        "        encoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = (\"encoder_layer_\"+ str(i) ))\n",
        "        encoder_outputs, state = encoder(encoder_outputs)\n",
        "      encoder_states = [state]\n",
        "\n",
        "      #---------------------------decoder ---------------------------------------------------\n",
        "      decoder_inputs = keras.Input(shape=(None, ))      \n",
        "      decoder_embedding_output = tf.keras.layers.Embedding(input_dim = self.num_decoder_tokens, output_dim = self.decoder_embed_size, name = \"decoder_embedding_layer\")(decoder_inputs)\n",
        "      \n",
        "      decoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True, dropout=self.dropout,use_bias=True, name = \"decoder_layer_0\")\n",
        "      decoder_outputs, _ = decoder(decoder_embedding_output, initial_state = encoder_states)\n",
        "      for i in range(1,self.num_decoder_layers):\n",
        "        decoder = keras.layers.GRU(self.hidden_layer_size, return_state=True,return_sequences=True,dropout=self.dropout,use_bias=True, name = (\"decoder_layer_\"+ str(i) ))\n",
        "        decoder_outputs, _ = decoder(decoder_outputs, initial_state = encoder_states)\n",
        "\n",
        "\n",
        "    decoder_dense = keras.layers.Dense(self.num_decoder_tokens, activation = self.activation,use_bias=True, name = \"dense\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    \n",
        "    #-----------------compile the model -------------------------------------\n",
        "    model.compile(\n",
        "         optimizer=self.optimizer,\n",
        "         loss=\"categorical_crossentropy\",\n",
        "         metrics=[\"accuracy\"]\n",
        "         ) \n",
        "\n",
        "#-------------------------- return final model ---------------------------------------------------------\n",
        "    return model\n",
        "\n",
        "#########################################function for training the model ###########################################\n",
        "\n",
        "  def train_model(self,encoder_input_data,decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "                  val_encoder_input_data, val_decoder_input_data, val_decoder_target_data):\n",
        "    \n",
        "     model=self.build_model()\n",
        "  \n",
        "     model.fit(\n",
        "        [encoder_input_data, decoder_input_data],\n",
        "        decoder_target_data,\n",
        "        batch_size = batch_size,\n",
        "        epochs = epochs,\n",
        "        validation_data = ([val_encoder_input_data, val_decoder_input_data],val_decoder_target_data),\n",
        "        callbacks=[EarlyStopping(patience = 5)]\n",
        "        )\n",
        "     return model\n",
        "\n",
        "#########################################function for inference on the model ###########################################\n",
        "\n",
        "  def sampling_inference(self, model, num_encoder_layers, num_decoder_layers):\n",
        "     \n",
        "     # Initialsiations\n",
        "     encoder_model = None\n",
        "     decoder_model = None\n",
        "\n",
        "     \n",
        "\n",
        "     #--------------------------------------if cell type = LSTM ----------------------------------------------------------\n",
        "     if self.cell_type ==\"lstm\":\n",
        "        #-----------------------------------encoder layers-------------------------------------\n",
        "\n",
        "        #constants\n",
        "        e_inputs = model.input[0]  # input_1\n",
        "        e_embed_layer = model.get_layer(\"encoder_embedding_layer\")\n",
        "        encoder_inputs = e_embed_layer(e_inputs)\n",
        "\n",
        "        #encoder cell layers\n",
        "        encoder_cell = None\n",
        "        for i in range(0, num_encoder_layers-1):\n",
        "          encoder_cell = model.get_layer(\"encoder_layer_\" + str(i))\n",
        "          encoder_inputs, _, _ = encoder_cell(encoder_inputs)\n",
        "        encoder_cell = model.get_layer(\"encoder_layer_\" + str(num_encoder_layers-1))\n",
        "        encoder_outputs, state_h_enc, state_c_enc = encoder_cell(encoder_inputs)\n",
        "        encoder_states = [state_h_enc, state_c_enc]\n",
        "\n",
        "        #encoder model\n",
        "        encoder_model = keras.Model(e_inputs, encoder_states)\n",
        "\n",
        "        #-----------------------------------decoder layers-------------------------------------\n",
        "\n",
        "        #constants\n",
        "        d_inputs = model.input[1] #input_2\n",
        "        d_embed_layer = model.get_layer(\"decoder_embedding_layer\")\n",
        "        decoder_inputs = d_embed_layer(d_inputs)\n",
        "        decoder_state_input_h = keras.Input(shape=(self.hidden_layer_size,), name=\"input_decoder_h\")\n",
        "        decoder_state_input_c = keras.Input(shape=(self.hidden_layer_size,), name=\"input_decoder_c\")\n",
        "        decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "        #decoder cell layers\n",
        "        decoder_cell = None\n",
        "        for i in range(0, num_decoder_layers-1):\n",
        "          decoder_cell = model.get_layer(\"decoder_layer_\" + str(i))\n",
        "          decoder_inputs, _, _ = decoder_cell(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "        decoder_cell = model.get_layer(\"decoder_layer_\" + str(num_decoder_layers-1))\n",
        "        decoder_inputs, state_h_dec, state_c_dec = decoder_cell(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "        decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "        #dense layer and decoder model     \n",
        "        decoder_dense = model.get_layer(\"dense\")\n",
        "        decoder_outputs = decoder_dense(decoder_inputs)\n",
        "        decoder_model = keras.Model([d_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "\n",
        "     #-------------------------------------if cell type =Simple RNN or GRU---------------------------------------------\n",
        "     elif self.cell_type ==\"rnn\" or self.cell_type ==\"gru\":\n",
        "\n",
        "        #-----------------------------------encoder layers-------------------------------------\n",
        "        #constants\n",
        "        e_inputs = model.input[0]  # input_1\n",
        "        e_embed_layer = model.get_layer(\"encoder_embedding_layer\")\n",
        "        encoder_inputs = e_embed_layer(e_inputs)\n",
        "\n",
        "        #encoder cell layers\n",
        "        encoder_cell = None\n",
        "        for i in range(0, num_encoder_layers-1):\n",
        "          encoder_cell = model.get_layer(\"encoder_layer_\" + str(i))\n",
        "          encoder_inputs, _ = encoder_cell(encoder_inputs)\n",
        "        encoder_cell = model.get_layer(\"encoder_layer_\" + str(num_encoder_layers-1))\n",
        "        encoder_outputs, state_h_enc = encoder_cell(encoder_inputs)\n",
        "        encoder_states = [state_h_enc]\n",
        "\n",
        "        #encoder model\n",
        "        encoder_model = keras.Model(e_inputs, encoder_states)\n",
        "\n",
        "        #-----------------------------------decoder layers-------------------------------------\n",
        "\n",
        "        #constants\n",
        "        d_inputs = model.input[1] #input_2\n",
        "        d_embed_layer = model.get_layer(\"decoder_embedding_layer\")\n",
        "        decoder_inputs = d_embed_layer(d_inputs)\n",
        "        decoder_state_input_h = keras.Input(shape=(self.hidden_layer_size,), name=\"input_decoder_h\")\n",
        "        decoder_state_inputs = [decoder_state_input_h]\n",
        "\n",
        "        #decoder cell layers\n",
        "        decoder_cell = None\n",
        "        for i in range(0, num_decoder_layers-1):\n",
        "          decoder_cell = model.get_layer(\"decoder_layer_\"+str(i))\n",
        "          decoder_inputs, _ = decoder_cell(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "        decoder_cell = model.get_layer(\"decoder_layer_\" + str(num_decoder_layers-1))\n",
        "        decoder_inputs, state_h_dec = decoder_cell(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "        decoder_states = [state_h_dec]\n",
        "\n",
        "        #dense layer and decoder model        \n",
        "        decoder_dense = model.get_layer(\"dense\")\n",
        "        decoder_outputs = decoder_dense(decoder_inputs)\n",
        "        decoder_model = keras.Model([d_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "     reverse_input_char_index = dict((i, char) for char, i in self.input_token_index.items())\n",
        "     reverse_target_char_index = dict((i, char) for char, i in self.target_token_index.items())\n",
        "     return (reverse_input_char_index,reverse_target_char_index, encoder_model, decoder_model)\n",
        "\n",
        "\n",
        "\n",
        "##################################################function for decoding input sequence ###########################################\n",
        "\n",
        "  def decode_sequence(self, input_data, encoder_model, decoder_model, max_decoder_seq_length, target_token_index):\n",
        "\n",
        "    num_examples = input_data.shape[0]\n",
        "    max_encoder_seq_length = input_data.shape[0]\n",
        "\n",
        "    # raw form of predictions to be returned\n",
        "    predicted_output = np.full((num_examples, max_decoder_seq_length), target_token_index[\" \"])\n",
        "\n",
        "    # ------ -----------if cell type=LSTM ---------------------------------\n",
        "    if self.cell_type ==\"lstm\":\n",
        "      states_value = encoder_model.predict(input_data[:num_examples,:])\n",
        "      target_seq = np.zeros((num_examples, 1),dtype=\"int32\")\n",
        "      target_seq[:, 0] = self.target_token_index[\"\\t\"]  \n",
        "\n",
        "    # ------ -----------if cell type= Simple RNN or GRU --------------------\n",
        "    elif self.cell_type == \"rnn\" or self.cell_type ==\"gru\":\n",
        "      states_value = (encoder_model.predict(input_data[:num_examples,:]))\n",
        "      target_seq = np.zeros((num_examples, 1),dtype=\"int32\")\n",
        "      target_seq[:, 0] = self.target_token_index[\"\\t\"]  \n",
        "\n",
        "    for i in range(max_decoder_seq_length):\n",
        "      # ------------------if cell type=LSTM ---------------------------------\n",
        "      if self.cell_type ==\"lstm\":\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        states_value = [h, c]\n",
        "      # ------------------if cell type= Simple RNN or GRU --------------------\n",
        "      elif self.cell_type ==\"rnn\" or self.cell_type ==\"gru\":\n",
        "        output_tokens, h = decoder_model.predict([target_seq] + [states_value])\n",
        "        states_value = [h] \n",
        "\n",
        "      for j in range(num_examples):\n",
        "        target_seq[j,0] = np.argmax(output_tokens[j, -1, :])\n",
        "        if target_seq[j,0] == target_token_index[\"\\n\"]:\n",
        "          predicted_output[j,i] = target_token_index[\" \"]\n",
        "        else:\n",
        "          predicted_output[j,i] = target_seq[j,0]\n",
        "\n",
        "  #--------------------------- return predictions ------------------------------\n",
        "    return predicted_output\n",
        "  \n",
        "  ##################################################function for calculating accuracy ###########################################\n",
        "\n",
        "  def calculate_accuracy(self, output_corpus, input_data, reverse_target_char_index, encoder_model, decoder_model):\n",
        "    \n",
        "    limit = input_data.shape[0]   \n",
        "\n",
        "    ########################### creating vectorised form of true output ###############################\n",
        "    true_output = np.full((limit, self.max_decoder_seq_length), self.target_token_index[\" \"])\n",
        "    for row in range(limit):\n",
        "      example = output_corpus[row].replace(\"\\n\",\"\").replace(\"\\t\",\"\")\n",
        "      for col in range(len(example)):\n",
        "        true_output[row][col] = self.target_token_index[example[col]]\n",
        "    \n",
        "    ########################### creating vectorised form of predicted output ###############################\n",
        "    predicted_output = self.decode_sequence(input_data, encoder_model, decoder_model, self.max_decoder_seq_length, target_token_index)\n",
        "\n",
        "    ########################### calculating accuracy ###############################\n",
        "    A = true_output\n",
        "    B = predicted_output \n",
        "    accuracy = (np.count_nonzero((A == B).all(1))/A.shape[0])    \n",
        "\n",
        "    return accuracy\n",
        "\n",
        "#===================================== end of class Machine_Transliterator ==========================================\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH8MZK3IPERe"
      },
      "source": [
        "**PREPROCESSING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYj3x6F4SNTm"
      },
      "source": [
        "############################# preprocessing the data ################################\n",
        "\n",
        "(encoder_input_data,decoder_input_data,decoder_target_data, _, _)=data(train_data_path,input_token_index,target_token_index)\n",
        "(val_encoder_input_data,val_decoder_input_data,val_decoder_target_data, val_target_texts, val_input_texts)=data(validation_data_path ,input_token_index,target_token_index)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGu0vosaNV4N"
      },
      "source": [
        "(t_encoder_input_data,t_decoder_input_data,t_decoder_target_data, t_target_texts, t_input_texts)=data(test_data_path ,input_token_index,target_token_index)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p26zuUhdj-e"
      },
      "source": [
        "**PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vw1sfMmdg45"
      },
      "source": [
        "cell_type = \"lstm\"\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 30  # Number of epochs to train for.\n",
        "hidden_layer_size = 128  # Latent dimensionality of the encoding space.\n",
        "activation = \"softmax\"\n",
        "optimizer = \"Adam\"\n",
        "encoder_embed_size = 64 #Encoder embedsize\n",
        "decoder_embed_size = 64 #Decoder embedsize\n",
        "num_encoder_layers = 3  # number of hidden layers in encoder\n",
        "num_decoder_layers = 1    # number of hidden layers in decoder\n",
        "dropout = 0.1 #Dropout"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ksIw3vH3XJ"
      },
      "source": [
        "**CREATING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F7lOm3MzREt"
      },
      "source": [
        "########################### creating machine transliterator object ###############################\n",
        "\n",
        "machine = Machine_Transliterator(\n",
        "      max_encoder_seq_length,max_decoder_seq_length,encoder_embed_size, \n",
        "      decoder_embed_size,num_encoder_layers,num_decoder_layers,\n",
        "      batch_size, hidden_layer_size, num_encoder_tokens, cell_type, num_decoder_tokens, \n",
        "      input_token_index,target_token_index, activation, optimizer,dropout\n",
        "      )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFA6z-vAjLPE"
      },
      "source": [
        "**TRAINING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHv1nsNfd6DQ",
        "outputId": "1b8c8c45-fb73-4a1f-b8c3-6e240aa5ea92"
      },
      "source": [
        "################################# Training the Model ############################################\n",
        "\n",
        "model = machine.train_model(\n",
        "      encoder_input_data, decoder_input_data,decoder_target_data,epochs,batch_size,\n",
        "      val_encoder_input_data, val_decoder_input_data, val_decoder_target_data\n",
        "      )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "691/691 [==============================] - 46s 16ms/step - loss: 1.3727 - accuracy: 0.6951 - val_loss: 0.9242 - val_accuracy: 0.7517\n",
            "Epoch 2/30\n",
            "691/691 [==============================] - 10s 14ms/step - loss: 0.9463 - accuracy: 0.7436 - val_loss: 0.8431 - val_accuracy: 0.7662\n",
            "Epoch 3/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.8577 - accuracy: 0.7618 - val_loss: 0.7623 - val_accuracy: 0.7841\n",
            "Epoch 4/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.7663 - accuracy: 0.7824 - val_loss: 0.6715 - val_accuracy: 0.8047\n",
            "Epoch 5/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.6753 - accuracy: 0.8055 - val_loss: 0.5832 - val_accuracy: 0.8308\n",
            "Epoch 6/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.5836 - accuracy: 0.8303 - val_loss: 0.4905 - val_accuracy: 0.8537\n",
            "Epoch 7/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.4877 - accuracy: 0.8546 - val_loss: 0.4108 - val_accuracy: 0.8765\n",
            "Epoch 8/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.4075 - accuracy: 0.8773 - val_loss: 0.3479 - val_accuracy: 0.8950\n",
            "Epoch 9/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.3442 - accuracy: 0.8954 - val_loss: 0.2983 - val_accuracy: 0.9101\n",
            "Epoch 10/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.2952 - accuracy: 0.9101 - val_loss: 0.2666 - val_accuracy: 0.9197\n",
            "Epoch 11/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.2572 - accuracy: 0.9210 - val_loss: 0.2405 - val_accuracy: 0.9271\n",
            "Epoch 12/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.2287 - accuracy: 0.9297 - val_loss: 0.2221 - val_accuracy: 0.9325\n",
            "Epoch 13/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.2053 - accuracy: 0.9362 - val_loss: 0.2104 - val_accuracy: 0.9351\n",
            "Epoch 14/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1906 - accuracy: 0.9406 - val_loss: 0.1975 - val_accuracy: 0.9397\n",
            "Epoch 15/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1758 - accuracy: 0.9450 - val_loss: 0.1944 - val_accuracy: 0.9399\n",
            "Epoch 16/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1648 - accuracy: 0.9485 - val_loss: 0.1903 - val_accuracy: 0.9412\n",
            "Epoch 17/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1541 - accuracy: 0.9518 - val_loss: 0.1844 - val_accuracy: 0.9437\n",
            "Epoch 18/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1455 - accuracy: 0.9543 - val_loss: 0.1821 - val_accuracy: 0.9437\n",
            "Epoch 19/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1368 - accuracy: 0.9569 - val_loss: 0.1786 - val_accuracy: 0.9451\n",
            "Epoch 20/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1311 - accuracy: 0.9587 - val_loss: 0.1778 - val_accuracy: 0.9457\n",
            "Epoch 21/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1243 - accuracy: 0.9609 - val_loss: 0.1745 - val_accuracy: 0.9463\n",
            "Epoch 22/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1161 - accuracy: 0.9632 - val_loss: 0.1751 - val_accuracy: 0.9468\n",
            "Epoch 23/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1115 - accuracy: 0.9649 - val_loss: 0.1746 - val_accuracy: 0.9471\n",
            "Epoch 24/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1070 - accuracy: 0.9661 - val_loss: 0.1741 - val_accuracy: 0.9468\n",
            "Epoch 25/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.1024 - accuracy: 0.9675 - val_loss: 0.1750 - val_accuracy: 0.9476\n",
            "Epoch 26/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.0987 - accuracy: 0.9688 - val_loss: 0.1776 - val_accuracy: 0.9470\n",
            "Epoch 27/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.0923 - accuracy: 0.9705 - val_loss: 0.1778 - val_accuracy: 0.9480\n",
            "Epoch 28/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.0913 - accuracy: 0.9706 - val_loss: 0.1774 - val_accuracy: 0.9475\n",
            "Epoch 29/30\n",
            "691/691 [==============================] - 9s 14ms/step - loss: 0.0859 - accuracy: 0.9724 - val_loss: 0.1787 - val_accuracy: 0.9481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYUULis2eAo1"
      },
      "source": [
        "################################# Building Inference Models ############################################\n",
        "\n",
        "(reverse_input_char_index,reverse_target_char_index, encoder_model, decoder_model) = machine.sampling_inference(model, num_encoder_layers, num_decoder_layers)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDB5L6TDeDRv",
        "outputId": "514eb6d7-ee2e-487c-91c1-2cd01e7e229c"
      },
      "source": [
        "################################# Validation Accuracy ############################################\n",
        "\n",
        "val_acc = machine.calculate_accuracy(val_target_texts, val_encoder_input_data, reverse_target_char_index, encoder_model, decoder_model)\n",
        "print(val_acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3517668655346489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGoIxI1seH5S",
        "outputId": "e288e76d-a861-4af3-b1bd-d5d68892c9d8"
      },
      "source": [
        "################################# Testing Accuracy ############################################\n",
        "\n",
        "test_acc = machine.calculate_accuracy(t_target_texts, t_encoder_input_data, reverse_target_char_index, encoder_model, decoder_model)\n",
        "print(test_acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3422923145268769\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}